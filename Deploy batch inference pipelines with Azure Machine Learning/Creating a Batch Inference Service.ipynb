{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace\r\n",
        "\r\n",
        "ws = Workspace.from_config()"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1661509477465
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Registering Model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\r\n",
        "from azureml.core import Model\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import joblib\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.metrics import roc_auc_score\r\n",
        "from sklearn.metrics import roc_curve\r\n",
        "\r\n",
        "# Create an Azure ML experiment in your workspace\r\n",
        "experiment = Experiment(workspace=ws, name='mslearn-train-diabetes')\r\n",
        "run = experiment.start_logging()\r\n",
        "print(\"Starting experiment:\", experiment.name)\r\n",
        "\r\n",
        "# load the diabetes dataset\r\n",
        "print(\"Loading Data...\")\r\n",
        "diabetes = pd.read_csv('data/diabetes.csv')\r\n",
        "\r\n",
        "# Separate features and labels\r\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\r\n",
        "\r\n",
        "# Split data into training set and test set\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\r\n",
        "\r\n",
        "# Train a decision tree model\r\n",
        "print('Training a decision tree model')\r\n",
        "model = DecisionTreeClassifier().fit(X_train, y_train)\r\n",
        "\r\n",
        "# calculate accuracy\r\n",
        "y_hat = model.predict(X_test)\r\n",
        "acc = np.average(y_hat == y_test)\r\n",
        "print('Accuracy:', acc)\r\n",
        "run.log('Accuracy', np.float(acc))\r\n",
        "\r\n",
        "# calculate AUC\r\n",
        "y_scores = model.predict_proba(X_test)\r\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\r\n",
        "print('AUC: ' + str(auc))\r\n",
        "run.log('AUC', np.float(auc))\r\n",
        "\r\n",
        "# Save the trained model\r\n",
        "model_file = 'diabetes_model.pkl'\r\n",
        "joblib.dump(value=model, filename=model_file)\r\n",
        "run.upload_file(name = 'outputs/' + model_file, path_or_stream = './' + model_file)\r\n",
        "\r\n",
        "# Complete the run\r\n",
        "run.complete()\r\n",
        "\r\n",
        "# Register the model\r\n",
        "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\r\n",
        "                   tags={'Training context':'Inline Training'},\r\n",
        "                   properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\r\n",
        "\r\n",
        "print('Model trained and registered.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Starting experiment: mslearn-train-diabetes\nLoading Data...\nTraining a decision tree model\nAccuracy: 0.8873333333333333\nAUC: 0.8738743221055774\nModel trained and registered.\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661509496107
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate and upload batch data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Datastore, Dataset\r\n",
        "import pandas as pd \r\n",
        "import os \r\n",
        "\r\n",
        "# Set default data store\r\n",
        "ws.set_default_datastore('workspaceblobstore')\r\n",
        "default_ds = ws.get_default_datastore()\r\n",
        "\r\n",
        "# Enumerate all datastore, indicating which is the default\r\n",
        "for ds_name in ws.datastores:\r\n",
        "    print(ds_name, \"- Default =\", ds_name == default_ds.name)\r\n",
        "\r\n",
        "# Load the diabetes data\r\n",
        "diabetes = pd.read_csv('data/diabetes2.csv')\r\n",
        "\r\n",
        "# Get a 100-item sample of the feature columns (not the diabetic label)\r\n",
        "sample = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].sample(n=100).values\r\n",
        "\r\n",
        "# Create a folder\r\n",
        "batch_folder = './batch-data'\r\n",
        "os.makedirs(batch_folder, exist_ok = True)\r\n",
        "\r\n",
        "print(\"Folder Created..!\")\r\n",
        "\r\n",
        "# Save each sample as a seperate file\r\n",
        "print(\"Saving files...\")\r\n",
        "for i in range(100):\r\n",
        "    fname = str(i + 1) + '.csv'\r\n",
        "    sample[i].tofile(os.path.join(batch_folder, fname), sep = \",\")\r\n",
        "\r\n",
        "print(\"Files saved\")\r\n",
        "\r\n",
        "# Upload the files to the default datastore\r\n",
        "print(\"Uploading files to datastore...\")\r\n",
        "default_ds = ws.get_default_datastore()\r\n",
        "default_ds.upload(src_dir = \"batch-data\", target_path = \"batch-data\", overwrite = True, show_progress = True)\r\n",
        "\r\n",
        "# Register a dataset for the input data\r\n",
        "batch_data_set = Dataset.File.from_files(path = (default_ds, 'batch-data/'), validate = False)\r\n",
        "\r\n",
        "try:\r\n",
        "    batch_data_set = batch_data_set.register(workspace = ws, name = 'batch-data', description = 'batch data', create_new_version = True)\r\n",
        "\r\n",
        "except Exception as ex:\r\n",
        "    print(ex)\r\n",
        "\r\n",
        "print(\"Done!\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "azureml_globaldatasets - Default = False\nworkspaceworkingdirectory - Default = False\nworkspaceartifactstore - Default = False\nworkspacefilestore - Default = False\nworkspaceblobstore - Default = True\nFolder Created..!\nSaving files...\nFiles saved\nUploading files to datastore...\nUploading an estimated of 102 files\nUploading batch-data/.amlignore\nUploaded batch-data/.amlignore, 1 files out of an estimated total of 102\nUploading batch-data/.amlignore.amltmp\nUploaded batch-data/.amlignore.amltmp, 2 files out of an estimated total of 102\nUploading batch-data/1.csv\nUploaded batch-data/1.csv, 3 files out of an estimated total of 102\nUploading batch-data/10.csv\nUploaded batch-data/10.csv, 4 files out of an estimated total of 102\nUploading batch-data/100.csv\nUploaded batch-data/100.csv, 5 files out of an estimated total of 102\nUploading batch-data/11.csv\nUploaded batch-data/11.csv, 6 files out of an estimated total of 102\nUploading batch-data/12.csv\nUploaded batch-data/12.csv, 7 files out of an estimated total of 102\nUploading batch-data/13.csv\nUploaded batch-data/13.csv, 8 files out of an estimated total of 102\nUploading batch-data/14.csv\nUploaded batch-data/14.csv, 9 files out of an estimated total of 102\nUploading batch-data/15.csv\nUploaded batch-data/15.csv, 10 files out of an estimated total of 102\nUploading batch-data/16.csv\nUploaded batch-data/16.csv, 11 files out of an estimated total of 102\nUploading batch-data/17.csv\nUploaded batch-data/17.csv, 12 files out of an estimated total of 102\nUploading batch-data/18.csv\nUploaded batch-data/18.csv, 13 files out of an estimated total of 102\nUploading batch-data/19.csv\nUploaded batch-data/19.csv, 14 files out of an estimated total of 102\nUploading batch-data/2.csv\nUploaded batch-data/2.csv, 15 files out of an estimated total of 102\nUploading batch-data/20.csv\nUploaded batch-data/20.csv, 16 files out of an estimated total of 102\nUploading batch-data/21.csv\nUploaded batch-data/21.csv, 17 files out of an estimated total of 102\nUploading batch-data/22.csv\nUploaded batch-data/22.csv, 18 files out of an estimated total of 102\nUploading batch-data/23.csv\nUploaded batch-data/23.csv, 19 files out of an estimated total of 102\nUploading batch-data/24.csv\nUploaded batch-data/24.csv, 20 files out of an estimated total of 102\nUploading batch-data/25.csv\nUploaded batch-data/25.csv, 21 files out of an estimated total of 102\nUploading batch-data/26.csv\nUploaded batch-data/26.csv, 22 files out of an estimated total of 102\nUploading batch-data/27.csv\nUploaded batch-data/27.csv, 23 files out of an estimated total of 102\nUploading batch-data/28.csv\nUploaded batch-data/28.csv, 24 files out of an estimated total of 102\nUploading batch-data/29.csv\nUploaded batch-data/29.csv, 25 files out of an estimated total of 102\nUploading batch-data/3.csv\nUploaded batch-data/3.csv, 26 files out of an estimated total of 102\nUploading batch-data/30.csv\nUploaded batch-data/30.csv, 27 files out of an estimated total of 102\nUploading batch-data/31.csv\nUploaded batch-data/31.csv, 28 files out of an estimated total of 102\nUploading batch-data/32.csv\nUploaded batch-data/32.csv, 29 files out of an estimated total of 102\nUploading batch-data/33.csv\nUploaded batch-data/33.csv, 30 files out of an estimated total of 102\nUploading batch-data/34.csv\nUploaded batch-data/34.csv, 31 files out of an estimated total of 102\nUploading batch-data/35.csv\nUploaded batch-data/35.csv, 32 files out of an estimated total of 102\nUploading batch-data/39.csv\nUploaded batch-data/39.csv, 33 files out of an estimated total of 102\nUploading batch-data/36.csv\nUploaded batch-data/36.csv, 34 files out of an estimated total of 102\nUploading batch-data/37.csv\nUploaded batch-data/37.csv, 35 files out of an estimated total of 102\nUploading batch-data/38.csv\nUploaded batch-data/38.csv, 36 files out of an estimated total of 102\nUploading batch-data/4.csv\nUploaded batch-data/4.csv, 37 files out of an estimated total of 102\nUploading batch-data/40.csv\nUploaded batch-data/40.csv, 38 files out of an estimated total of 102\nUploading batch-data/41.csv\nUploaded batch-data/41.csv, 39 files out of an estimated total of 102\nUploading batch-data/42.csv\nUploaded batch-data/42.csv, 40 files out of an estimated total of 102\nUploading batch-data/43.csv\nUploaded batch-data/43.csv, 41 files out of an estimated total of 102\nUploading batch-data/44.csv\nUploaded batch-data/44.csv, 42 files out of an estimated total of 102\nUploading batch-data/45.csv\nUploaded batch-data/45.csv, 43 files out of an estimated total of 102\nUploading batch-data/46.csv\nUploaded batch-data/46.csv, 44 files out of an estimated total of 102\nUploading batch-data/47.csv\nUploaded batch-data/47.csv, 45 files out of an estimated total of 102\nUploading batch-data/48.csv\nUploaded batch-data/48.csv, 46 files out of an estimated total of 102\nUploading batch-data/49.csv\nUploaded batch-data/49.csv, 47 files out of an estimated total of 102\nUploading batch-data/5.csv\nUploaded batch-data/5.csv, 48 files out of an estimated total of 102\nUploading batch-data/50.csv\nUploaded batch-data/50.csv, 49 files out of an estimated total of 102\nUploading batch-data/51.csv\nUploaded batch-data/51.csv, 50 files out of an estimated total of 102\nUploading batch-data/52.csv\nUploaded batch-data/52.csv, 51 files out of an estimated total of 102\nUploading batch-data/53.csv\nUploaded batch-data/53.csv, 52 files out of an estimated total of 102\nUploading batch-data/54.csv\nUploaded batch-data/54.csv, 53 files out of an estimated total of 102\nUploading batch-data/55.csv\nUploaded batch-data/55.csv, 54 files out of an estimated total of 102\nUploading batch-data/56.csv\nUploaded batch-data/56.csv, 55 files out of an estimated total of 102\nUploading batch-data/57.csv\nUploaded batch-data/57.csv, 56 files out of an estimated total of 102\nUploading batch-data/58.csv\nUploaded batch-data/58.csv, 57 files out of an estimated total of 102\nUploading batch-data/59.csv\nUploaded batch-data/59.csv, 58 files out of an estimated total of 102\nUploading batch-data/6.csv\nUploaded batch-data/6.csv, 59 files out of an estimated total of 102\nUploading batch-data/60.csv\nUploaded batch-data/60.csv, 60 files out of an estimated total of 102\nUploading batch-data/61.csv\nUploaded batch-data/61.csv, 61 files out of an estimated total of 102\nUploading batch-data/62.csv\nUploaded batch-data/62.csv, 62 files out of an estimated total of 102\nUploading batch-data/63.csv\nUploaded batch-data/63.csv, 63 files out of an estimated total of 102\nUploading batch-data/64.csv\nUploaded batch-data/64.csv, 64 files out of an estimated total of 102\nUploading batch-data/65.csv\nUploaded batch-data/65.csv, 65 files out of an estimated total of 102\nUploading batch-data/66.csv\nUploaded batch-data/66.csv, 66 files out of an estimated total of 102\nUploading batch-data/67.csv\nUploaded batch-data/67.csv, 67 files out of an estimated total of 102\nUploading batch-data/68.csv\nUploaded batch-data/68.csv, 68 files out of an estimated total of 102\nUploading batch-data/69.csv\nUploaded batch-data/69.csv, 69 files out of an estimated total of 102\nUploading batch-data/7.csv\nUploaded batch-data/7.csv, 70 files out of an estimated total of 102\nUploading batch-data/70.csv\nUploaded batch-data/70.csv, 71 files out of an estimated total of 102\nUploading batch-data/71.csv\nUploaded batch-data/71.csv, 72 files out of an estimated total of 102\nUploading batch-data/72.csv\nUploaded batch-data/72.csv, 73 files out of an estimated total of 102\nUploading batch-data/73.csv\nUploaded batch-data/73.csv, 74 files out of an estimated total of 102\nUploading batch-data/74.csv\nUploaded batch-data/74.csv, 75 files out of an estimated total of 102\nUploading batch-data/75.csv\nUploaded batch-data/75.csv, 76 files out of an estimated total of 102\nUploading batch-data/76.csv\nUploaded batch-data/76.csv, 77 files out of an estimated total of 102\nUploading batch-data/77.csv\nUploaded batch-data/77.csv, 78 files out of an estimated total of 102\nUploading batch-data/78.csv\nUploaded batch-data/78.csv, 79 files out of an estimated total of 102\nUploading batch-data/79.csv\nUploaded batch-data/79.csv, 80 files out of an estimated total of 102\nUploading batch-data/8.csv\nUploaded batch-data/8.csv, 81 files out of an estimated total of 102\nUploading batch-data/80.csv\nUploaded batch-data/80.csv, 82 files out of an estimated total of 102\nUploading batch-data/81.csv\nUploaded batch-data/81.csv, 83 files out of an estimated total of 102\nUploading batch-data/82.csv\nUploaded batch-data/82.csv, 84 files out of an estimated total of 102\nUploading batch-data/83.csv\nUploaded batch-data/83.csv, 85 files out of an estimated total of 102\nUploading batch-data/84.csv\nUploaded batch-data/84.csv, 86 files out of an estimated total of 102\nUploading batch-data/85.csv\nUploaded batch-data/85.csv, 87 files out of an estimated total of 102\nUploading batch-data/86.csv\nUploaded batch-data/86.csv, 88 files out of an estimated total of 102\nUploading batch-data/87.csv\nUploaded batch-data/87.csv, 89 files out of an estimated total of 102\nUploading batch-data/88.csv\nUploaded batch-data/88.csv, 90 files out of an estimated total of 102\nUploading batch-data/89.csv\nUploaded batch-data/89.csv, 91 files out of an estimated total of 102\nUploading batch-data/9.csv\nUploaded batch-data/9.csv, 92 files out of an estimated total of 102\nUploading batch-data/90.csv\nUploaded batch-data/90.csv, 93 files out of an estimated total of 102\nUploading batch-data/91.csv\nUploaded batch-data/91.csv, 94 files out of an estimated total of 102\nUploading batch-data/92.csv\nUploaded batch-data/92.csv, 95 files out of an estimated total of 102\nUploading batch-data/93.csv\nUploaded batch-data/93.csv, 96 files out of an estimated total of 102\nUploading batch-data/94.csv\nUploaded batch-data/94.csv, 97 files out of an estimated total of 102\nUploading batch-data/95.csv\nUploaded batch-data/95.csv, 98 files out of an estimated total of 102\nUploading batch-data/96.csv\nUploaded batch-data/96.csv, 99 files out of an estimated total of 102\nUploading batch-data/97.csv\nUploaded batch-data/97.csv, 100 files out of an estimated total of 102\nUploading batch-data/98.csv\nUploaded batch-data/98.csv, 101 files out of an estimated total of 102\nUploading batch-data/99.csv\nUploaded batch-data/99.csv, 102 files out of an estimated total of 102\nUploaded 102 files\nDone!\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\"Datastore.upload\" is deprecated after version 1.0.69. Please use \"Dataset.File.upload_directory\" to upload your files             from a local directory and create FileDataset in single method call. See Dataset API change notice at https://aka.ms/dataset-deprecation.\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661509524229
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Compute"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "\r\n",
        "cluster_name = 'your-compute-cluster'\r\n",
        "\r\n",
        "try:\r\n",
        "    inference_cluster = ComputeTarget(ws, cluster_name)\r\n",
        "    print(\"Found existing cluster, use it.\")\r\n",
        "\r\n",
        "except ComputeTargetException:\r\n",
        "    try:\r\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\r\n",
        "        inference_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\r\n",
        "\r\n",
        "        inference_cluster.wait_for_completion(show_output = True)\r\n",
        "    \r\n",
        "    except Exception as ex:\r\n",
        "        print(ex)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing cluster, use it.\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661509524483
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline for batch inferencing"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "\r\n",
        "experiment_folder = 'batch_pipeline'\r\n",
        "os.makedirs(experiment_folder, exist_ok=True)\r\n",
        "\r\n",
        "print(experiment_folder)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "batch_pipeline\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661509731705
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/batch_diabetes.py\r\n",
        "\r\n",
        "import os \r\n",
        "import numpy as np \r\n",
        "from azureml.core import Model \r\n",
        "import joblib \r\n",
        "\r\n",
        "def init():\r\n",
        "\r\n",
        "    global model \r\n",
        "\r\n",
        "    model_path = Model.get_model_path('diabetes_model')\r\n",
        "    model = joblib.load(model_path) \r\n",
        "\r\n",
        "def run(mini_batch):\r\n",
        "\r\n",
        "    resultList = []\r\n",
        "\r\n",
        "    for f in mini_batch:\r\n",
        "        data = np.genfromtxt(f, delimiter = ',')\r\n",
        "        prediction = model.predict(data.reshape(1, -1))\r\n",
        "        resultList.append(\"{}: {}\".format(os.path.basename(f), prediction[0])) \r\n",
        "    \r\n",
        "    return resultList"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting batch_pipeline/batch_diabetes.py\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/batch_environment.yml\r\n",
        "\r\n",
        "name: batch_environment\r\n",
        "dependencies:\r\n",
        "- python=3.6.2\r\n",
        "- scikit-learn\r\n",
        "- pip\r\n",
        "- pip:\r\n",
        "    - azureml-defaults"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting batch_pipeline/batch_environment.yml\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\r\n",
        "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\r\n",
        "\r\n",
        "batch_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/batch_environment.yml\")\r\n",
        "batch_env.docker.base_image = DEFAULT_CPU_IMAGE\r\n",
        "print('Configuration ready.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Configuration ready.\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661509524864
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.steps import ParallelRunConfig, ParallelRunStep\r\n",
        "from azureml.data import OutputFileDatasetConfig\r\n",
        "\r\n",
        "output_dir = OutputFileDatasetConfig(name = 'inferences')\r\n",
        "\r\n",
        "paralell_run_config = ParallelRunConfig(\r\n",
        "    source_directory = experiment_folder,\r\n",
        "    entry_script = 'batch_diabetes.py',\r\n",
        "    mini_batch_size = \"5\",\r\n",
        "    error_threshold = 10,\r\n",
        "    output_action = 'append_row',\r\n",
        "    environment = batch_env,\r\n",
        "    compute_target = inference_cluster,\r\n",
        "    node_count = 2\r\n",
        ")\r\n",
        "\r\n",
        "paralellrun_step = ParallelRunStep(\r\n",
        "    name = 'batch-score-diabetes',\r\n",
        "    parallel_run_config = paralell_run_config,\r\n",
        "    inputs = [batch_data_set.as_named_input('diabetes_batch')],\r\n",
        "    output = output_dir,\r\n",
        "    arguments = [],\r\n",
        "    allow_reuse = True\r\n",
        ")\r\n",
        "\r\n",
        "print('Steps are defined')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Steps are defined\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661510109502
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\r\n",
        "from azureml.pipeline.core import Pipeline\r\n",
        "\r\n",
        "pipeline = Pipeline(workspace = ws, steps = [paralellrun_step])\r\n",
        "pipeline_run = Experiment(ws, 'mslearn-diabetes-batch').submit(pipeline)\r\n",
        "pipeline_run.wait_for_completion(show_output = True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Created step batch-score-diabetes [d30b5e20][65bd5e8b-af0b-4a0b-b4be-1222e1ac3a55], (This step will run and generate new outputs)\nSubmitted PipelineRun 026e297e-0475-4900-8c4a-42cbb33a064f\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/026e297e-0475-4900-8c4a-42cbb33a064f?wsid=/subscriptions/3571f8dc-3527-4993-9d2b-ac0812d807fd/resourcegroups/aml-resources/workspaces/aml-workspace&tid=78c76086-2fb7-4f6a-b684-c129ba0ea713\nPipelineRunId: 026e297e-0475-4900-8c4a-42cbb33a064f\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/026e297e-0475-4900-8c4a-42cbb33a064f?wsid=/subscriptions/3571f8dc-3527-4993-9d2b-ac0812d807fd/resourcegroups/aml-resources/workspaces/aml-workspace&tid=78c76086-2fb7-4f6a-b684-c129ba0ea713\nPipelineRun Status: NotStarted\nPipelineRun Status: Running\n\n\nStepRunId: 9658f6fa-1814-4415-a08c-dee2897bfd53\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/9658f6fa-1814-4415-a08c-dee2897bfd53?wsid=/subscriptions/3571f8dc-3527-4993-9d2b-ac0812d807fd/resourcegroups/aml-resources/workspaces/aml-workspace&tid=78c76086-2fb7-4f6a-b684-c129ba0ea713\nStepRun( batch-score-diabetes ) Status: Running\n\nStreaming azureml-logs/20_image_build_log.txt\n=============================================\n2022/08/26 10:37:48 Downloading source code...\n2022/08/26 10:37:55 Finished downloading source code\n2022/08/26 10:37:55 Creating Docker network: acb_default_network, driver: 'bridge'\n2022/08/26 10:37:55 Successfully set up Docker network: acb_default_network\n2022/08/26 10:37:55 Setting up Docker configuration...\n2022/08/26 10:37:56 Successfully set up Docker configuration\n2022/08/26 10:37:56 Logging in to registry: c2708a96e5904d4fa0c490f52e02261e.azurecr.io\n2022/08/26 10:37:57 Successfully logged into c2708a96e5904d4fa0c490f52e02261e.azurecr.io\n2022/08/26 10:37:57 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n2022/08/26 10:37:57 Scanning for dependencies...\n2022/08/26 10:37:58 Successfully scanned dependencies\n2022/08/26 10:37:58 Launching container with name: acb_step_0\nSending build context to Docker daemon  66.56kB\n\nStep 1/21 : FROM mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220616.v1@sha256:2e18aafa005c25d3e0200d9dd39255ef5a30680a569cd1c3326fd65f5989db47\nmcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220616.v1@sha256:2e18aafa005c25d3e0200d9dd39255ef5a30680a569cd1c3326fd65f5989db47: Pulling from azureml/openmpi4.1.0-ubuntu20.04\nd7bfe07ed847: Pulling fs layer\ndcef2ac699a5: Pulling fs layer\n42794fc92dfd: Pulling fs layer\n88af38890981: Pulling fs layer\n13e568c28e4b: Pulling fs layer\n18f510a7158e: Pulling fs layer\n8699f484c7da: Pulling fs layer\na7071d489c78: Pulling fs layer\nfd21b2f1d9b3: Pulling fs layer\nfe7fa5ee3450: Pulling fs layer\n88af38890981: Waiting\n13e568c28e4b: Waiting\n18f510a7158e: Waiting\n8699f484c7da: Waiting\na7071d489c78: Waiting\nfd21b2f1d9b3: Waiting\nfe7fa5ee3450: Waiting\n42794fc92dfd: Verifying Checksum\n42794fc92dfd: Download complete\nd7bfe07ed847: Verifying Checksum\nd7bfe07ed847: Download complete\n88af38890981: Verifying Checksum\n88af38890981: Download complete\n13e568c28e4b: Verifying Checksum\n13e568c28e4b: Download complete\n8699f484c7da: Verifying Checksum\n8699f484c7da: Download complete\na7071d489c78: Verifying Checksum\na7071d489c78: Download complete\ndcef2ac699a5: Verifying Checksum\ndcef2ac699a5: Download complete\n18f510a7158e: Verifying Checksum\n18f510a7158e: Download complete\nfd21b2f1d9b3: Verifying Checksum\nfd21b2f1d9b3: Download complete\nfe7fa5ee3450: Verifying Checksum\nfe7fa5ee3450: Download complete\nd7bfe07ed847: Pull complete\ndcef2ac699a5: Pull complete\n42794fc92dfd: Pull complete\n88af38890981: Pull complete\n13e568c28e4b: Pull complete\n18f510a7158e: Pull complete\n8699f484c7da: Pull complete\na7071d489c78: Pull complete\nfd21b2f1d9b3: Pull complete\nfe7fa5ee3450: Pull complete\nDigest: sha256:2e18aafa005c25d3e0200d9dd39255ef5a30680a569cd1c3326fd65f5989db47\nStatus: Downloaded newer image for mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220616.v1@sha256:2e18aafa005c25d3e0200d9dd39255ef5a30680a569cd1c3326fd65f5989db47\n ---> 14dd8bce8bd3\nStep 2/21 : USER root\n ---> Running in d2f24594964e\nRemoving intermediate container d2f24594964e\n ---> fd43bd626a9e\nStep 3/21 : RUN mkdir -p $HOME/.cache\n ---> Running in 8391badc36eb\nRemoving intermediate container 8391badc36eb\n ---> 50d48f284ba1\nStep 4/21 : WORKDIR /\n ---> Running in fa0feb6ec71d\nRemoving intermediate container fa0feb6ec71d\n ---> df3db422215a\nStep 5/21 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n ---> 931b48609371\nStep 6/21 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n ---> Running in a6816f43c2f9\nRemoving intermediate container a6816f43c2f9\n ---> b5b09f99107e\nStep 7/21 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n ---> 5805c68b398a\nStep 8/21 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n ---> Running in 2c6567511357\nCollecting package metadata (repodata.json): ...working... done\nSolving environment: ...working... done\n\nDownloading and Extracting Packages\n\nmkl_fft-1.3.0        | 170 KB    |            |   0% \nmkl_fft-1.3.0        | 170 KB    | ########## | 100% \n\nzlib-1.2.12          | 106 KB    |            |   0% \nzlib-1.2.12          | 106 KB    | ########## | 100% \n\npip-21.2.2           | 1.8 MB    |            |   0% \npip-21.2.2           | 1.8 MB    | ########## | 100% \npip-21.2.2           | 1.8 MB    | ########## | 100% \n\nopenssl-1.0.2u       | 2.2 MB    |            |   0% \nopenssl-1.0.2u       | 2.2 MB    | ########## | 100% \n\nlibgcc-ng-11.2.0     | 5.3 MB    |            |   0% \nlibgcc-ng-11.2.0     | 5.3 MB    | ########## | 100% \nlibgcc-ng-11.2.0     | 5.3 MB    | ########## | 100% \n\n_libgcc_mutex-0.1    | 3 KB      |            |   0% \n_libgcc_mutex-0.1    | 3 KB      | ########## | 100% \n\nca-certificates-2022 | 124 KB    |            |   0% \nca-certificates-2022 | 124 KB    | ########## | 100% \n\nlibffi-3.2.1         | 48 KB     |            |   0% \nlibffi-3.2.1         | 48 KB     | ########## | 100% \n\nlibstdcxx-ng-11.2.0  | 4.7 MB    |            |   0% \nlibstdcxx-ng-11.2.0  | 4.7 MB    | ########## | 100% \nlibstdcxx-ng-11.2.0  | 4.7 MB    | ########## | 100% \n\nxz-5.2.5             | 339 KB    |            |   0% \nxz-5.2.5             | 339 KB    | ########## | 100% \n\nthreadpoolctl-2.2.0  | 16 KB     |            |   0% \nthreadpoolctl-2.2.0  | 16 KB     | ########## | 100% \n\nlibedit-3.1          | 151 KB    |            |   0% \nlibedit-3.1          | 151 KB    | ########## | 100% \n\nmkl_random-1.1.1     | 327 KB    |            |   0% \nmkl_random-1.1.1     | 327 KB    | ########## | 100% \n\nmkl-service-2.3.0    | 52 KB     |            |   0% \nmkl-service-2.3.0    | 52 KB     | ########## | 100% \n\nscikit-learn-0.24.2  | 5.2 MB    |            |   0% \nscikit-learn-0.24.2  | 5.2 MB    | ########## | 100% \nscikit-learn-0.24.2  | 5.2 MB    | ########## | 100% \n\nnumpy-1.19.2         | 22 KB     |            |   0% \nnumpy-1.19.2         | 22 KB     | ########## | 100% \n\nncurses-6.0          | 781 KB    |            |   0% \nncurses-6.0          | 781 KB    | ########## | 100% \nncurses-6.0          | 781 KB    | ########## | 100% \n\nsqlite-3.23.1        | 808 KB    |            |   0% \nsqlite-3.23.1        | 808 KB    | ########## | 100% \n\ntk-8.6.12            | 3.0 MB    |            |   0% \ntk-8.6.12            | 3.0 MB    | ########## | 100% \ntk-8.6.12            | 3.0 MB    | ########## | 100% \n\nnumpy-base-1.19.2    | 4.1 MB    |            |   0% \nnumpy-base-1.19.2    | 4.1 MB    | ########## | 100% \nnumpy-base-1.19.2    | 4.1 MB    | ########## | 100% \n\nintel-openmp-2022.0. | 4.2 MB    |            |   0% \nintel-openmp-2022.0. | 4.2 MB    | ########## | 100% \nintel-openmp-2022.0. | 4.2 MB    | ########## | 100% \n\nsetuptools-58.0.4    | 788 KB    |            |   0% \nsetuptools-58.0.4    | 788 KB    | ########## | 100% \n\n_openmp_mutex-5.1    | 21 KB     |            |   0% \n_openmp_mutex-5.1    | 21 KB     | ########## | 100% \n\njoblib-1.0.1         | 208 KB    |            |   0% \njoblib-1.0.1         | 208 KB    | ########## | 100% \n\nmkl-2020.2           | 138.3 MB  |            |   0% \nmkl-2020.2           | 138.3 MB  | 5          |   6% \nmkl-2020.2           | 138.3 MB  | #1         |  12% \nmkl-2020.2           | 138.3 MB  | #8         |  18% \nmkl-2020.2           | 138.3 MB  | ##7        |  28% \nmkl-2020.2           | 138.3 MB  | ###5       |  35% \nmkl-2020.2           | 138.3 MB  | ####1      |  42% \nmkl-2020.2           | 138.3 MB  | ####8      |  49% \nmkl-2020.2           | 138.3 MB  | #####8     |  58% \nmkl-2020.2           | 138.3 MB  | ######8    |  68% \nmkl-2020.2           | 138.3 MB  | #######6   |  77% \nmkl-2020.2           | 138.3 MB  | ########7  |  87% \nmkl-2020.2           | 138.3 MB  | #########5 |  96% \nmkl-2020.2           | 138.3 MB  | ########## | 100% \n\nreadline-7.0         | 848 KB    |            |   0% \nreadline-7.0         | 848 KB    | ########## | 100% \n\nsix-1.16.0           | 18 KB     |            |   0% \nsix-1.16.0           | 18 KB     | ########## | 100% \n\nlibgfortran4-7.5.0   | 995 KB    |            |   0% \nlibgfortran4-7.5.0   | 995 KB    | ########## | 100% \n\npython-3.6.2         | 23.6 MB   |            |   0% \npython-3.6.2         | 23.6 MB   | ###9       |  40% \npython-3.6.2         | 23.6 MB   | ########5  |  86% \npython-3.6.2         | 23.6 MB   | ########## | 100% \n\ncertifi-2021.5.30    | 139 KB    |            |   0% \ncertifi-2021.5.30    | 139 KB    | ########## | 100% \n\nscipy-1.5.2          | 14.4 MB   |            |   0% \nscipy-1.5.2          | 14.4 MB   | ######2    |  62% \nscipy-1.5.2          | 14.4 MB   | ########## | 100% \n\nlibgomp-11.2.0       | 474 KB    |            |   0% \nlibgomp-11.2.0       | 474 KB    | ########## | 100% \n\nwheel-0.37.1         | 33 KB     |            |   0% \nwheel-0.37.1         | 33 KB     | ########## | 100% \n\nblas-1.0             | 6 KB      |            |   0% \nblas-1.0             | 6 KB      | ########## | 100% \n\nlibgfortran-ng-7.5.0 | 22 KB     |            |   0% \nlibgfortran-ng-7.5.0 | 22 KB     | ########## | 100% \nPreparing transaction: ...working... done\nVerifying transaction: ...working... done\nExecuting transaction: ...working... \n\n    Installed package of scikit-learn can be accelerated using scikit-learn-intelex.\n    More details are available here: https://intel.github.io/scikit-learn-intelex\n\n    For example:\n\n        $ conda install scikit-learn-intelex\n        $ python -m sklearnex my_application.py\n\n    \n\ndone\nInstalling pip dependencies: ...working... \nRan pip subprocess with arguments:\n['/azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.1pw9sgtr.requirements.txt']\nPip subprocess output:\nCollecting azureml-defaults\n  Downloading azureml_defaults-1.44.0-py3-none-any.whl (2.0 kB)\nCollecting azureml-core~=1.44.0\n  Downloading azureml_core-1.44.0-py3-none-any.whl (2.7 MB)\nCollecting configparser==3.7.4\n  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\nCollecting azureml-inference-server-http~=0.7.2\n  Downloading azureml_inference_server_http-0.7.5-py3-none-any.whl (56 kB)\nCollecting json-logging-py==0.2\n  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\nCollecting azureml-dataset-runtime[fuse]~=1.44.0\n  Downloading azureml_dataset_runtime-1.44.0-py3-none-any.whl (2.3 kB)\nCollecting jmespath<=1.0.0\n  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\nCollecting PyJWT<3.0.0\n  Downloading PyJWT-2.4.0-py3-none-any.whl (18 kB)\nCollecting docker<6.0.0\n  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\nCollecting msrest<=0.7.1,>=0.5.1\n  Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\nCollecting backports.tempfile\n  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\nCollecting ndg-httpsclient<=0.5.1\n  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\nCollecting azure-graphrbac<1.0.0,>=0.40.0\n  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\nCollecting azure-core<2.0.0\n  Downloading azure_core-1.24.2-py3-none-any.whl (178 kB)\nCollecting argcomplete<3\n  Downloading argcomplete-2.0.0-py2.py3-none-any.whl (37 kB)\nCollecting msal-extensions<=1.0.0,>=0.3.0\n  Downloading msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB)\nCollecting azure-common<2.0.0,>=1.1.12\n  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\nCollecting contextlib2<22.0.0\n  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\nCollecting azure-mgmt-resource<22.0.0,>=15.0.0\n  Downloading azure_mgmt_resource-21.1.0-py3-none-any.whl (1.8 MB)\nCollecting azure-mgmt-keyvault<11.0.0,>=0.40.0\n  Downloading azure_mgmt_keyvault-10.0.0-py3-none-any.whl (489 kB)\nCollecting pytz\n  Downloading pytz-2022.2.1-py2.py3-none-any.whl (500 kB)\nCollecting jsonpickle<3.0.0\n  Downloading jsonpickle-2.2.0-py2.py3-none-any.whl (39 kB)\nCollecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<38.0.0\n  Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\nCollecting pyopenssl<23.0.0\n  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\nCollecting msal<2.0.0,>=1.15.0\n  Downloading msal-1.18.0-py2.py3-none-any.whl (82 kB)\nCollecting azure-mgmt-storage<=20.0.0,>=16.0.0\n  Downloading azure_mgmt_storage-20.0.0-py3-none-any.whl (2.0 MB)\nCollecting adal<=1.2.7,>=1.2.0\n  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\nCollecting azure-mgmt-containerregistry<11,>=8.2.0\n  Downloading azure_mgmt_containerregistry-10.0.0-py3-none-any.whl (1.2 MB)\nCollecting knack~=0.9.0\n  Downloading knack-0.9.0-py3-none-any.whl (59 kB)\nCollecting requests[socks]<3.0.0,>=2.19.1\n  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\nCollecting python-dateutil<3.0.0,>=2.7.3\n  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\nCollecting urllib3<=1.26.9,>=1.23\n  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\nCollecting packaging<22.0,>=20.0\n  Downloading packaging-21.3-py3-none-any.whl (40 kB)\nCollecting SecretStorage<4.0.0\n  Downloading SecretStorage-3.3.3-py3-none-any.whl (15 kB)\nCollecting paramiko<3.0.0,>=2.0.8\n  Downloading paramiko-2.11.0-py2.py3-none-any.whl (212 kB)\nCollecting azure-mgmt-authorization<3,>=0.40.0\n  Downloading azure_mgmt_authorization-2.0.0-py2.py3-none-any.whl (465 kB)\nCollecting pkginfo\n  Downloading pkginfo-1.8.3-py2.py3-none-any.whl (26 kB)\nCollecting pathspec<1.0.0\n  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\nCollecting msrestazure<=0.6.4,>=0.4.33\n  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\nCollecting humanfriendly<11.0,>=4.7\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\nCollecting importlib-metadata<5,>=0.23\n  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\nRequirement already satisfied: six>=1.11.0 in /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/lib/python3.6/site-packages (from azure-core<2.0.0->azureml-core~=1.44.0->azureml-defaults->-r /azureml-environment-setup/condaenv.1pw9sgtr.requirements.txt (line 1)) (1.16.0)\nCollecting typing-extensions>=4.0.1\n  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\nCollecting azure-mgmt-core<2.0.0,>=1.2.0\n  Downloading azure_mgmt_core-1.3.2-py3-none-any.whl (26 kB)\nCollecting pyarrow<6.0.1,>=0.17.0\n  Downloading pyarrow-6.0.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.5 MB)\nRequirement already satisfied: numpy!=1.19.3 in /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/lib/python3.6/site-packages (from azureml-dataset-runtime[fuse]~=1.44.0->azureml-defaults->-r /azureml-environment-setup/condaenv.1pw9sgtr.requirements.txt (line 1)) (1.19.2)\nCollecting azureml-dataprep<4.3.0a,>=4.2.0a\n  Downloading azureml_dataprep-4.2.2-py3-none-any.whl (43.4 MB)\nCollecting fusepy<4.0.0,>=3.0.1\n  Downloading fusepy-3.0.1.tar.gz (11 kB)\nCollecting pyyaml<7.0.0,>=5.1.0\n  Downloading PyYAML-6.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (603 kB)\nCollecting azure-identity==1.7.0\n  Downloading azure_identity-1.7.0-py2.py3-none-any.whl (129 kB)\nCollecting azureml-dataprep-native<39.0.0,>=38.0.0\n  Downloading azureml_dataprep_native-38.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\nCollecting cloudpickle<3.0.0,>=1.1.0\n  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\nCollecting jsonschema\n  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\nCollecting dotnetcore2<4.0.0,>=3.0.0\n  Downloading dotnetcore2-3.1.23-py3-none-manylinux1_x86_64.whl (31.1 MB)\nCollecting azureml-dataprep-rslex~=2.8.0dev0\n  Downloading azureml_dataprep_rslex-2.8.1-cp36-cp36m-manylinux2010_x86_64.whl (16.5 MB)\nCollecting msal-extensions<=1.0.0,>=0.3.0\n  Downloading msal_extensions-0.3.1-py2.py3-none-any.whl (18 kB)\nCollecting flask-cors~=3.0.1\n  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\nCollecting gunicorn==20.1.0\n  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\nCollecting inference-schema~=1.4.0\n  Downloading inference_schema-1.4.2.1-py3-none-any.whl (21 kB)\nCollecting flask<2.2.0\n  Downloading Flask-2.0.3-py3-none-any.whl (95 kB)\nCollecting opencensus-ext-azure~=1.1.0\n  Downloading opencensus_ext_azure-1.1.7-py2.py3-none-any.whl (42 kB)\nRequirement already satisfied: setuptools>=3.0 in /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/lib/python3.6/site-packages (from gunicorn==20.1.0->azureml-inference-server-http~=0.7.2->azureml-defaults->-r /azureml-environment-setup/condaenv.1pw9sgtr.requirements.txt (line 1)) (58.0.4)\nCollecting cffi>=1.12\n  Downloading cffi-1.15.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (402 kB)\nCollecting pycparser\n  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\nCollecting websocket-client>=0.32.0\n  Downloading websocket_client-1.3.1-py3-none-any.whl (54 kB)\nCollecting distro>=1.2.0\n  Downloading distro-1.7.0-py3-none-any.whl (20 kB)\nCollecting click>=7.1.2\n  Downloading click-8.0.4-py3-none-any.whl (97 kB)\nCollecting Jinja2>=3.0\n  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\nCollecting Werkzeug>=2.0\n  Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\nCollecting itsdangerous>=2.0\n  Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)\nCollecting zipp>=0.5\n  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\nCollecting wrapt<=1.12.1,>=1.11.1\n  Downloading wrapt-1.12.1.tar.gz (27 kB)\nCollecting MarkupSafe>=2.0\n  Downloading MarkupSafe-2.0.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (30 kB)\nCollecting pygments\n  Downloading Pygments-2.13.0-py3-none-any.whl (1.1 MB)\nCollecting tabulate\n  Downloading tabulate-0.8.10-py3-none-any.whl (29 kB)\nCollecting portalocker<3,>=1.0\n  Downloading portalocker-2.5.1-py2.py3-none-any.whl (15 kB)\nCollecting isodate>=0.6.0\n  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\nRequirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/lib/python3.6/site-packages (from msrest<=0.7.1,>=0.5.1->azureml-core~=1.44.0->azureml-defaults->-r /azureml-environment-setup/condaenv.1pw9sgtr.requirements.txt (line 1)) (2021.5.30)\nCollecting requests-oauthlib>=0.5.0\n  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\nCollecting pyasn1>=0.1.1\n  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\nCollecting psutil>=5.6.3\n  Downloading psutil-5.9.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\nCollecting opencensus<1.0.0,>=0.11.0\n  Downloading opencensus-0.11.0-py2.py3-none-any.whl (128 kB)\nCollecting opencensus-context>=0.1.3\n  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\nCollecting google-api-core<3.0.0,>=1.0.0\n  Downloading google_api_core-2.8.2-py3-none-any.whl (114 kB)\nCollecting googleapis-common-protos<2.0dev,>=1.56.2\n  Downloading googleapis_common_protos-1.56.3-py2.py3-none-any.whl (211 kB)\nCollecting google-auth<3.0dev,>=1.25.0\n  Downloading google_auth-2.11.0-py2.py3-none-any.whl (167 kB)\nCollecting protobuf<5.0.0dev,>=3.15.0\n  Downloading protobuf-3.19.4-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\nCollecting pyasn1-modules>=0.2.1\n  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\nCollecting rsa<5,>=3.1.4\n  Downloading rsa-4.9-py3-none-any.whl (34 kB)\nCollecting cachetools<6.0,>=2.0.0\n  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\nCollecting contextvars\n  Downloading contextvars-2.4.tar.gz (9.6 kB)\nCollecting pyparsing!=3.0.5,>=2.0.2\n  Downloading pyparsing-3.0.7-py3-none-any.whl (98 kB)\nCollecting bcrypt>=3.1.3\n  Downloading bcrypt-4.0.0-cp36-abi3-manylinux_2_28_x86_64.whl (594 kB)\nCollecting pynacl>=1.0.1\n  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\nCollecting idna<4,>=2.5\n  Downloading idna-3.3-py3-none-any.whl (61 kB)\nCollecting charset-normalizer~=2.0.0\n  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\nCollecting oauthlib>=3.0.0\n  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\nCollecting PySocks!=1.5.7,>=1.5.6\n  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\nCollecting jeepney>=0.6\n  Downloading jeepney-0.7.1-py3-none-any.whl (54 kB)\nCollecting dataclasses\n  Downloading dataclasses-0.8-py3-none-any.whl (19 kB)\nCollecting backports.weakref\n  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\nCollecting immutables>=0.9\n  Downloading immutables-0.18-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (115 kB)\nCollecting pyrsistent>=0.14.0\n  Downloading pyrsistent-0.18.0-cp36-cp36m-manylinux1_x86_64.whl (117 kB)\nCollecting attrs>=17.4.0\n  Downloading attrs-22.1.0-py2.py3-none-any.whl (58 kB)\nBuilding wheels for collected packages: json-logging-py, fusepy, wrapt, contextvars\n  Building wheel for json-logging-py (setup.py): started\n  Building wheel for json-logging-py (setup.py): finished with status 'done'\n  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3924 sha256=b3eb29f316aab299e90c9bc77aa63b2955398f32d0eef3b8a913d09204c6be15\n  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\n  Building wheel for fusepy (setup.py): started\n  Building wheel for fusepy (setup.py): finished with status 'done'\n  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10503 sha256=5e995cc3e371a952f445d2d88bc8a630f7b3a94761244cc04bca6716f1b86ddb\n  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n  Building wheel for wrapt (setup.py): started\n  Building wheel for wrapt (setup.py): finished with status 'done'\n  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=76180 sha256=b273ef2ea5d498fb22ea4db5770467ba3b68ebf32a6da62ca8ca1b63c36f8a46\n  Stored in directory: /root/.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\n  Building wheel for contextvars (setup.py): started\n  Building wheel for contextvars (setup.py): finished with status 'done'\n  Created wheel for contextvars: filename=contextvars-2.4-py3-none-any.whl size=7681 sha256=119ee2a21a52d08399817ce6882d0cec75dbff2d7c27250d8a374952b396605e\n  Stored in directory: /root/.cache/pip/wheels/41/11/53/911724983aa48deb94792432e14e518447212dd6c5477d49d3\nSuccessfully built json-logging-py fusepy wrapt contextvars\nInstalling collected packages: pycparser, cffi, urllib3, PyJWT, idna, cryptography, charset-normalizer, typing-extensions, requests, pyasn1, zipp, rsa, pyasn1-modules, protobuf, portalocker, oauthlib, msal, immutables, cachetools, requests-oauthlib, python-dateutil, pyrsistent, msal-extensions, MarkupSafe, isodate, importlib-metadata, googleapis-common-protos, google-auth, distro, dataclasses, contextvars, azure-core, attrs, Werkzeug, pyyaml, opencensus-context, msrest, jsonschema, Jinja2, itsdangerous, google-api-core, dotnetcore2, cloudpickle, click, azureml-dataprep-rslex, azureml-dataprep-native, azure-identity, adal, wrapt, websocket-client, tabulate, pytz, PySocks, pyparsing, pyopenssl, pynacl, pygments, pyarrow, psutil, opencensus, msrestazure, jmespath, jeepney, flask, bcrypt, backports.weakref, azureml-dataprep, azure-mgmt-core, azure-common, argcomplete, SecretStorage, pkginfo, pathspec, paramiko, packaging, opencensus-ext-azure, ndg-httpsclient, knack, jsonpickle, inference-schema, humanfriendly, gunicorn, fusepy, flask-cors, docker, contextlib2, backports.tempfile, azureml-dataset-runtime, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, azure-graphrbac, json-logging-py, configparser, azureml-inference-server-http, azureml-core, azureml-defaults\nSuccessfully installed Jinja2-3.0.3 MarkupSafe-2.0.1 PyJWT-2.4.0 PySocks-1.7.1 SecretStorage-3.3.3 Werkzeug-2.0.3 adal-1.2.7 argcomplete-2.0.0 attrs-22.1.0 azure-common-1.1.28 azure-core-1.24.2 azure-graphrbac-0.61.1 azure-identity-1.7.0 azure-mgmt-authorization-2.0.0 azure-mgmt-containerregistry-10.0.0 azure-mgmt-core-1.3.2 azure-mgmt-keyvault-10.0.0 azure-mgmt-resource-21.1.0 azure-mgmt-storage-20.0.0 azureml-core-1.44.0 azureml-dataprep-4.2.2 azureml-dataprep-native-38.0.0 azureml-dataprep-rslex-2.8.1 azureml-dataset-runtime-1.44.0 azureml-defaults-1.44.0 azureml-inference-server-http-0.7.5 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-4.0.0 cachetools-4.2.4 cffi-1.15.1 charset-normalizer-2.0.12 click-8.0.4 cloudpickle-2.1.0 configparser-3.7.4 contextlib2-21.6.0 contextvars-2.4 cryptography-37.0.4 dataclasses-0.8 distro-1.7.0 docker-5.0.3 dotnetcore2-3.1.23 flask-2.0.3 flask-cors-3.0.10 fusepy-3.0.1 google-api-core-2.8.2 google-auth-2.11.0 googleapis-common-protos-1.56.3 gunicorn-20.1.0 humanfriendly-10.0 idna-3.3 immutables-0.18 importlib-metadata-4.8.3 inference-schema-1.4.2.1 isodate-0.6.1 itsdangerous-2.0.1 jeepney-0.7.1 jmespath-0.10.0 json-logging-py-0.2 jsonpickle-2.2.0 jsonschema-3.2.0 knack-0.9.0 msal-1.18.0 msal-extensions-0.3.1 msrest-0.7.1 msrestazure-0.6.4 ndg-httpsclient-0.5.1 oauthlib-3.2.0 opencensus-0.11.0 opencensus-context-0.1.3 opencensus-ext-azure-1.1.7 packaging-21.3 paramiko-2.11.0 pathspec-0.9.0 pkginfo-1.8.3 portalocker-2.5.1 protobuf-3.19.4 psutil-5.9.1 pyarrow-6.0.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycparser-2.21 pygments-2.13.0 pynacl-1.5.0 pyopenssl-22.0.0 pyparsing-3.0.7 pyrsistent-0.18.0 python-dateutil-2.8.2 pytz-2022.2.1 pyyaml-6.0 requests-2.27.1 requests-oauthlib-1.3.1 rsa-4.9 tabulate-0.8.10 typing-extensions-4.1.1 urllib3-1.26.9 websocket-client-1.3.1 wrapt-1.12.1 zipp-3.6.0\n\ndone\n#\n# To activate this environment, use\n#\n#     $ conda activate /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d\n#\n# To deactivate an active environment, use\n#\n#     $ conda deactivate\n\n\u001b[91m\n\n==> WARNING: A newer version of conda exists. <==\n  current version: 4.11.0\n  latest version: 4.14.0\n\nPlease update conda by running\n\n    $ conda update -n base -c defaults conda\n\n\n\u001b[0mWARNING: /root/.conda/pkgs does not exist\n\nRemoving intermediate container 2c6567511357\n ---> ca130bfe1fcf\nStep 9/21 : ENV PATH /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/bin:$PATH\n ---> Running in a07542ff7c32\nRemoving intermediate container a07542ff7c32\n ---> d034ea4c4dba\nStep 10/21 : COPY azureml-environment-setup/send_conda_dependencies.py azureml-environment-setup/send_conda_dependencies.py\n ---> 060ba8273108\nStep 11/21 : RUN echo \"Copying environment context\"\n ---> Running in c2b507c8fb58\nCopying environment context\nRemoving intermediate container c2b507c8fb58\n ---> a4aadbd31533\nStep 12/21 : COPY azureml-environment-setup/environment_context.json azureml-environment-setup/environment_context.json\n ---> d72ff698bb8e\nStep 13/21 : RUN python /azureml-environment-setup/send_conda_dependencies.py -p /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d\n ---> Running in 17121aaba37a\nReport materialized dependencies for the environment\nReading environment context\nExporting conda environment\nSending request with materialized conda environment details\nSuccessfully sent materialized environment details\nRemoving intermediate container 17121aaba37a\n ---> 8352c89d5e54\nStep 14/21 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d\n ---> Running in 077166f8b2a6\nRemoving intermediate container 077166f8b2a6\n ---> 2bdff151a0e9\nStep 15/21 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/lib:$LD_LIBRARY_PATH\n ---> Running in 9b1280d7ca30\nRemoving intermediate container 9b1280d7ca30\n ---> 4cf6406f2403\nStep 16/21 : ENV CONDA_DEFAULT_ENV=azureml_e220b045f6c3c3008b1a386af067185d CONDA_PREFIX=/azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d\n ---> Running in 8ce1715cbc40\nRemoving intermediate container 8ce1715cbc40\n ---> 15668c5135ac\nStep 17/21 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n ---> bba5a67a9cf4\nStep 18/21 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n ---> Running in b701c1c8acbd\nRemoving intermediate container b701c1c8acbd\n ---> 86d3ed575c49\nStep 19/21 : RUN rm -rf azureml-environment-setup\n ---> Running in 5fdba93a22af\nRemoving intermediate container 5fdba93a22af\n ---> 497ffb25c1b6\nStep 20/21 : ENV AZUREML_ENVIRONMENT_IMAGE True\n ---> Running in c737cb7ac323\nRemoving intermediate container c737cb7ac323\n ---> eecaa996afc9\nStep 21/21 : CMD [\"bash\"]\n ---> Running in 5815c52c626f\nRemoving intermediate container 5815c52c626f\n ---> cded5f088727\nSuccessfully built cded5f088727\nSuccessfully tagged c2708a96e5904d4fa0c490f52e02261e.azurecr.io/azureml/azureml_8c6bd2a1473ebdafead55f817061c00f:latest\nSuccessfully tagged c2708a96e5904d4fa0c490f52e02261e.azurecr.io/azureml/azureml_8c6bd2a1473ebdafead55f817061c00f:1\n2022/08/26 10:40:22 Successfully executed container: acb_step_0\n2022/08/26 10:40:22 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n2022/08/26 10:40:22 Pushing image: c2708a96e5904d4fa0c490f52e02261e.azurecr.io/azureml/azureml_8c6bd2a1473ebdafead55f817061c00f:1, attempt 1\nThe push refers to repository [c2708a96e5904d4fa0c490f52e02261e.azurecr.io/azureml/azureml_8c6bd2a1473ebdafead55f817061c00f]\n6afea2a58b68: Preparing\n23dc85213995: Preparing\na5912bdb2870: Preparing\nc64deaa4a6c0: Preparing\n09443e39bb69: Preparing\na94f44ba12ec: Preparing\n9016c74f1108: Preparing\nb89f1a21a9e2: Preparing\n301c1db15fc1: Preparing\n364c2c75084f: Preparing\nc839a7db4216: Preparing\n0e7fa8586520: Preparing\n5d42179dac11: Preparing\n427fe3399545: Preparing\nbb86fa0b2bb8: Preparing\nea56242f701b: Preparing\n15d0cbdd54cd: Preparing\n549ccbc27046: Preparing\ncecd54a2fd82: Preparing\naf7ed92504ae: Preparing\na94f44ba12ec: Waiting\n9016c74f1108: Waiting\nb89f1a21a9e2: Waiting\n301c1db15fc1: Waiting\n364c2c75084f: Waiting\n0e7fa8586520: Waiting\nc839a7db4216: Waiting\n5d42179dac11: Waiting\n549ccbc27046: Waiting\n427fe3399545: Waiting\nbb86fa0b2bb8: Waiting\nea56242f701b: Waiting\ncecd54a2fd82: Waiting\n15d0cbdd54cd: Waiting\naf7ed92504ae: Waiting\n6afea2a58b68: Pushed\n09443e39bb69: Pushed\n23dc85213995: Pushed\nc64deaa4a6c0: Pushed\na5912bdb2870: Pushed\n9016c74f1108: Pushed\nb89f1a21a9e2: Pushed\n301c1db15fc1: Pushed\n364c2c75084f: Pushed\nc839a7db4216: Pushed\n0e7fa8586520: Pushed\nea56242f701b: Pushed\n5d42179dac11: Pushed\n427fe3399545: Pushed\n15d0cbdd54cd: Pushed\n549ccbc27046: Pushed\naf7ed92504ae: Pushed\nbb86fa0b2bb8: Pushed\ncecd54a2fd82: Pushed\na94f44ba12ec: Pushed\n1: digest: sha256:d81ac2ecdf4f0dcce899fe4e4b85819b828fe1dae9eb13ae4fe33919d5551cdb size: 4513\n2022/08/26 10:41:55 Successfully pushed image: c2708a96e5904d4fa0c490f52e02261e.azurecr.io/azureml/azureml_8c6bd2a1473ebdafead55f817061c00f:1\n2022/08/26 10:41:55 Executing step ID: acb_step_2. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n2022/08/26 10:41:55 Pushing image: c2708a96e5904d4fa0c490f52e02261e.azurecr.io/azureml/azureml_8c6bd2a1473ebdafead55f817061c00f:latest, attempt 1\nThe push refers to repository [c2708a96e5904d4fa0c490f52e02261e.azurecr.io/azureml/azureml_8c6bd2a1473ebdafead55f817061c00f]\n6afea2a58b68: Preparing\n23dc85213995: Preparing\na5912bdb2870: Preparing\nc64deaa4a6c0: Preparing\n09443e39bb69: Preparing\na94f44ba12ec: Preparing\n9016c74f1108: Preparing\nb89f1a21a9e2: Preparing\n301c1db15fc1: Preparing\n364c2c75084f: Preparing\nc839a7db4216: Preparing\n0e7fa8586520: Preparing\n5d42179dac11: Preparing\n427fe3399545: Preparing\nbb86fa0b2bb8: Preparing\nea56242f701b: Preparing\n15d0cbdd54cd: Preparing\n549ccbc27046: Preparing\ncecd54a2fd82: Preparing\naf7ed92504ae: Preparing\n0e7fa8586520: Waiting\n5d42179dac11: Waiting\na94f44ba12ec: Waiting\n427fe3399545: Waiting\nbb86fa0b2bb8: Waiting\nea56242f701b: Waiting\n9016c74f1108: Waiting\n15d0cbdd54cd: Waiting\n549ccbc27046: Waiting\nb89f1a21a9e2: Waiting\ncecd54a2fd82: Waiting\n301c1db15fc1: Waiting\naf7ed92504ae: Waiting\n364c2c75084f: Waiting\nc839a7db4216: Waiting\na5912bdb2870: Layer already exists\n6afea2a58b68: Layer already exists\n09443e39bb69: Layer already exists\na94f44ba12ec: Layer already exists\n9016c74f1108: Layer already exists\nc64deaa4a6c0: Layer already exists\n23dc85213995: Layer already exists\n301c1db15fc1: Layer already exists\nb89f1a21a9e2: Layer already exists\nc839a7db4216: Layer already exists\n364c2c75084f: Layer already exists\n5d42179dac11: Layer already exists\n427fe3399545: Layer already exists\n0e7fa8586520: Layer already exists\nbb86fa0b2bb8: Layer already exists\n15d0cbdd54cd: Layer already exists\nea56242f701b: Layer already exists\n549ccbc27046: Layer already exists\ncecd54a2fd82: Layer already exists\naf7ed92504ae: Layer already exists\nlatest: digest: sha256:d81ac2ecdf4f0dcce899fe4e4b85819b828fe1dae9eb13ae4fe33919d5551cdb size: 4513\n2022/08/26 10:41:57 Successfully pushed image: c2708a96e5904d4fa0c490f52e02261e.azurecr.io/azureml/azureml_8c6bd2a1473ebdafead55f817061c00f:latest\n2022/08/26 10:41:57 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 145.365257)\n2022/08/26 10:41:57 Populating digests for step ID: acb_step_0...\n2022/08/26 10:41:58 Successfully populated digests for step ID: acb_step_0\n2022/08/26 10:41:58 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 92.945325)\n2022/08/26 10:41:58 Step ID: acb_step_2 marked as successful (elapsed time in seconds: 1.436237)\n2022/08/26 10:41:58 The following dependencies were found:\n2022/08/26 10:41:58 \n- image:\n    registry: c2708a96e5904d4fa0c490f52e02261e.azurecr.io\n    repository: azureml/azureml_8c6bd2a1473ebdafead55f817061c00f\n    tag: latest\n    digest: sha256:d81ac2ecdf4f0dcce899fe4e4b85819b828fe1dae9eb13ae4fe33919d5551cdb\n  runtime-dependency:\n    registry: mcr.microsoft.com\n    repository: azureml/openmpi4.1.0-ubuntu20.04\n    tag: 20220616.v1\n    digest: sha256:2e18aafa005c25d3e0200d9dd39255ef5a30680a569cd1c3326fd65f5989db47\n  git: {}\n- image:\n    registry: c2708a96e5904d4fa0c490f52e02261e.azurecr.io\n    repository: azureml/azureml_8c6bd2a1473ebdafead55f817061c00f\n    tag: \"1\"\n    digest: sha256:d81ac2ecdf4f0dcce899fe4e4b85819b828fe1dae9eb13ae4fe33919d5551cdb\n  runtime-dependency:\n    registry: mcr.microsoft.com\n    repository: azureml/openmpi4.1.0-ubuntu20.04\n    tag: 20220616.v1\n    digest: sha256:2e18aafa005c25d3e0200d9dd39255ef5a30680a569cd1c3326fd65f5989db47\n  git: {}\n\nRun ID: cu1 was successful after 4m11s\n\nStreaming azureml-logs/55_azureml-execution-tvmps_6920dc47fe48bffe69e0d940778b70bf4d99d1f37b655d6c605c31ee26934f31_d.txt\n========================================================================================================================\n2022-08-26T10:52:41Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/aml-workspace/azureml/9658f6fa-1814-4415-a08c-dee2897bfd53/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/aml-workspace/azureml/9658f6fa-1814-4415-a08c-dee2897bfd53/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=24614 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/aml-workspace/azureml/9658f6fa-1814-4415-a08c-dee2897bfd53/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n2022-08-26T10:52:41Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/aml-workspace/azureml/9658f6fa-1814-4415-a08c-dee2897bfd53/mounts/workspaceblobstore -- stdout/stderr: \n2022-08-26T10:52:42Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2022-08-26T10:52:42Z Starting output-watcher...\n2022-08-26T10:52:42Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n2022-08-26T10:52:42Z Executing 'Copy ACR Details file' on 10.0.0.5\n2022-08-26T10:52:42Z Executing 'Copy ACR Details file' on 10.0.0.4\n2022-08-26T10:52:42Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n>>>   \n>>>   \n2022-08-26T10:52:43Z Copy ACR Details file succeeded on 10.0.0.5. Output: \n>>>   \n70: Pulling from azureml/curated/sidecar\nd7bfe07ed847: Pulling fs layer\ndcef2ac699a5: Pulling fs layer\n42794fc92dfd: Pulling fs layer\n88af38890981: Pulling fs layer\n13e568c28e4b: Pulling fs layer\n18f510a7158e: Pulling fs layer\n8699f484c7da: Pulling fs layer\na7071d489c78: Pulling fs layer\nfd21b2f1d9b3: Pulling fs layer\nfe7fa5ee3450: Pulling fs layer\n2a563e3f81b0: Pulling fs layer\ndbc80e23976b: Pulling fs layer\n6b5e9388df31: Pulling fs layer\n758a21e0749e: Pulling fs layer\n8f938f45ed8d: Pulling fs layer\n4166290bcbdf: Pulling fs layer\n76cdfb5ed624: Pulling fs layer\n9148a687a452: Pulling fs layer\n4072ca38e5ac: Pulling fs layer\n2ded670cfa94: Pulling fs layer\n659846794281: Pulling fs layer\n194b3b1881f4: Pulling fs layer\n12f7815c54b8: Pulling fs layer\n88af38890981: Waiting\n13e568c28e4b: Waiting\n18f510a7158e: Waiting\n8699f484c7da: Waiting\na7071d489c78: Waiting\nfd21b2f1d9b3: Waiting\nfe7fa5ee3450: Waiting\n2a563e3f81b0: Waiting\ndbc80e23976b: Waiting\n6b5e9388df31: Waiting\n758a21e0749e: Waiting\n8f938f45ed8d: Waiting\n4166290bcbdf: Waiting\n76cdfb5ed624: Waiting\n9148a687a452: Waiting\n4072ca38e5ac: Waiting\n2ded670cfa94: Waiting\n659846794281: Waiting\n194b3b1881f4: Waiting\n12f7815c54b8: Waiting\n42794fc92dfd: Verifying Checksum\n42794fc92dfd: Download complete\nd7bfe07ed847: Verifying Checksum\nd7bfe07ed847: Download complete\n13e568c28e4b: Verifying Checksum\n13e568c28e4b: Download complete\n88af38890981: Verifying Checksum\n88af38890981: Download complete\n8699f484c7da: Verifying Checksum\n8699f484c7da: Download complete\n18f510a7158e: Verifying Checksum\n18f510a7158e: Download complete\na7071d489c78: Verifying Checksum\na7071d489c78: Download complete\nfe7fa5ee3450: Verifying Checksum\nfe7fa5ee3450: Download complete\nfd21b2f1d9b3: Verifying Checksum\nfd21b2f1d9b3: Download complete\ndcef2ac699a5: Verifying Checksum\ndcef2ac699a5: Download complete\ndbc80e23976b: Verifying Checksum\ndbc80e23976b: Download complete\n2a563e3f81b0: Verifying Checksum\n2a563e3f81b0: Download complete\n8f938f45ed8d: Verifying Checksum\n8f938f45ed8d: Download complete\n4166290bcbdf: Verifying Checksum\n4166290bcbdf: Download complete\n76cdfb5ed624: Verifying Checksum\n76cdfb5ed624: Download complete\nd7bfe07ed847: Pull complete\n9148a687a452: Verifying Checksum\n9148a687a452: Download complete\n758a21e0749e: Verifying Checksum\n758a21e0749e: Download complete\n4072ca38e5ac: Verifying Checksum\n4072ca38e5ac: Download complete\n2ded670cfa94: Verifying Checksum\n2ded670cfa94: Download complete\n659846794281: Verifying Checksum\n659846794281: Download complete\n194b3b1881f4: Verifying Checksum\n194b3b1881f4: Download complete\n12f7815c54b8: Verifying Checksum\n12f7815c54b8: Download complete\n6b5e9388df31: Verifying Checksum\n6b5e9388df31: Download complete\ndcef2ac699a5: Pull complete\n42794fc92dfd: Pull complete\n88af38890981: Pull complete\n13e568c28e4b: Pull complete\n18f510a7158e: Pull complete\n8699f484c7da: Pull complete\na7071d489c78: Pull complete\nfd21b2f1d9b3: Pull complete\nfe7fa5ee3450: Pull complete\n2a563e3f81b0: Pull complete\ndbc80e23976b: Pull complete\n6b5e9388df31: Pull complete\n758a21e0749e: Pull complete\n8f938f45ed8d: Pull complete\n4166290bcbdf: Pull complete\n76cdfb5ed624: Pull complete\n9148a687a452: Pull complete\n4072ca38e5ac: Pull complete\n2ded670cfa94: Pull complete\n659846794281: Pull complete\n194b3b1881f4: Pull complete\n12f7815c54b8: Pull complete\nDigest: sha256:c5931fb3fb96642b435e66bd759c6595577396ede63973b46a987e6398dd8690\nStatus: Downloaded newer image for mcr.microsoft.com/azureml/curated/sidecar:70\nmcr.microsoft.com/azureml/curated/sidecar:70\n2022-08-26T10:53:11Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2022-08-26T10:53:11Z Check if container 9658f6fa-1814-4415-a08c-dee2897bfd53_DataSidecar already exist exited with 0, \n\nb7d9e8318abe880f69a1be7bc7b667438a4afa23cebd4be2b13f9e70c280ddeb\n2022-08-26T10:53:12Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n2022-08-26T10:53:12Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-771b4a7686fb1caa885a64db53a8caba-22bd30933469ac4f-01 -sshRequired=false] \n2022/08/26 10:53:12 Didn't get JobInfoJson from env, now read from file\n2022/08/26 10:53:12 Suceeded read JobInfoJson from file\n2022/08/26 10:53:12 Starting App Insight Logger for task:  containerSetup\n2022/08/26 10:53:12 Version: 3.0.02046.0004 Branch: .SourceBranch Commit: a27c02c\n2022/08/26 10:53:12 Entered ContainerSetupTask - Preparing infiniband\n2022/08/26 10:53:12 Starting infiniband setup\n2022/08/26 10:53:12 Python Version found is Python 3.8.12\n\n2022/08/26 10:53:12 Returning Python Version as 3.8\n2022/08/26 10:53:12 VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-20.04\n2022/08/26 10:53:12 VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-20.04\n2022-08-26T10:53:12Z VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-20.04\n2022/08/26 10:53:12 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n2022/08/26 10:53:12 Not setting up Infiniband in Container\n2022/08/26 10:53:12 Not setting up Infiniband in Container\n2022-08-26T10:53:12Z Not setting up Infiniband in Container\n2022/08/26 10:53:12 Python Version found is Python 3.8.12\n\n2022/08/26 10:53:12 Returning Python Version as 3.8\n2022/08/26 10:53:12 sshd inside container not required for job, skipping setup.\n2022/08/26 10:53:13 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n2022/08/26 10:53:13 App Insight Client has already been closed\n2022/08/26 10:53:13 Not exporting to RunHistory as the exporter is either stopped or there is no data.\nStopped: false\nOriginalData: 1\nFilteredData: 0.\n2022-08-26T10:53:13Z Starting docker container succeeded.\n2022-08-26T10:53:13Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n\nStreaming azureml-logs/65_job_prep-tvmps_6920dc47fe48bffe69e0d940778b70bf4d99d1f37b655d6c605c31ee26934f31_d.txt\n===============================================================================================================\n[2022-08-26T10:53:15.069418] Entering job preparation.\n[2022-08-26T10:53:15.630093] Starting job preparation.\n[2022-08-26T10:53:15.630123] Extracting the control code.\n[2022-08-26T10:53:15.630531] Starting extract_project.\n[2022-08-26T10:53:15.630613] Starting to extract zip file.\n[2022-08-26T10:53:15.648674] Finished extracting zip file.\n[2022-08-26T10:53:15.652556] Using urllib.request Python 3.0 or later\n[2022-08-26T10:53:15.652593] Start fetching snapshots.\n[2022-08-26T10:53:15.652645] Start fetching snapshot.\nStarting the daemon thread to refresh tokens in background for process with pid = 49\n[2022-08-26T10:53:15.962713] Finished fetching snapshot.\n[2022-08-26T10:53:15.962744] Start fetching snapshot.\n[2022-08-26T10:53:23.336724] Finished fetching snapshot.\n[2022-08-26T10:53:23.336764] Finished fetching snapshots.\n[2022-08-26T10:53:23.336849] Finished extract_project.\n[2022-08-26T10:53:23.336967] Finished fetching and extracting the control code.\n[2022-08-26T10:53:23.343835] Start run_history_prep.\n[2022-08-26T10:53:23.350712] Job preparation is complete.\n[2022-08-26T10:53:23.350954] Entering Data Context Managers in Sidecar\n[2022-08-26T10:53:23.351812] Running Sidecar prep cmd...\n[2022-08-26T10:53:23.711434] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml-workspace/azureml/9658f6fa-1814-4415-a08c-dee2897bfd53/wd/azureml/9658f6fa-1814-4415-a08c-dee2897bfd53\n[2022-08-26T10:53:23.712735] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\"]}\n[2022-08-26T10:53:23.866] Enter __enter__ of DatasetContextManager\n[2022-08-26T10:53:23.868] SDK version: azureml-core==0.1.0.66253449 azureml-dataprep==4.1.0. Session id: 342e4ad0-d405-43e1-9a2d-45361716d1f8. Run id: 9658f6fa-1814-4415-a08c-dee2897bfd53.\n[2022-08-26T10:53:23.868] Processing 'diabetes_batch'.\n[2022-08-26T10:53:23.868] Mode: 'mount'.\n[2022-08-26T10:53:23.868] Path on compute is specified: 'False'.\n[2022-08-26T10:53:23.868] asset_type: None, is_eval_mode: False, is_legacy_dataset: False for input: diabetes_batch\n[2022-08-26T10:53:25.660] Processing dataset FileDataset\n{\n  \"source\": [\n    \"('workspaceblobstore', 'batch-data/')\"\n  ],\n  \"definition\": [\n    \"GetDatastoreFiles\"\n  ],\n  \"registration\": {\n    \"id\": \"31747bfe-20cb-4296-8624-265194a1a749\",\n    \"name\": \"batch-data\",\n    \"version\": 1,\n    \"description\": \"batch data\",\n    \"workspace\": \"Workspace.create(name='aml-workspace', subscription_id='3571f8dc-3527-4993-9d2b-ac0812d807fd', resource_group='aml-resources')\"\n  }\n}\n[2022-08-26T10:53:26.347] Mounting diabetes_batch to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml-workspace/azureml/9658f6fa-1814-4415-a08c-dee2897bfd53/wd/diabetes_batch_31747bfe-20cb-4296-8624-265194a1a749 as folder.\n[2022-08-26T10:53:26.348] Processing 'inferences'.\n[2022-08-26T10:53:26.348] Mode: 'mount'.\n[2022-08-26T10:53:26.348] Path on compute is specified: '/mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml-workspace/azureml/9658f6fa-1814-4415-a08c-dee2897bfd53/wd/inferences_workspaceblobstore'.\n[2022-08-26T10:53:26.429] Mounting inferences to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml-workspace/azureml/9658f6fa-1814-4415-a08c-dee2897bfd53/wd/inferences_workspaceblobstore\n[2022-08-26T10:53:26.429] Output is not a single file\n[2022-08-26T10:53:26.429] Mounted inferences to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml-workspace/azureml/9658f6fa-1814-4415-a08c-dee2897bfd53/wd/inferences_workspaceblobstore as folder\n[2022-08-26T10:53:27.973] Mounting INPUT_diabetes_batch to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml-workspace/azureml/9658f6fa-1814-4415-a08c-dee2897bfd53/wd/diabetes_batch_31747bfe-20cb-4296-8624-265194a1a749.\n[2022-08-26T10:53:28.976] Mounted INPUT_diabetes_batch to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml-workspace/azureml/9658f6fa-1814-4415-a08c-dee2897bfd53/wd/diabetes_batch_31747bfe-20cb-4296-8624-265194a1a749.\n[2022-08-26T10:53:28.976] Mounting inferences to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml-workspace/azureml/9658f6fa-1814-4415-a08c-dee2897bfd53/wd/inferences_workspaceblobstore.\n[2022-08-26T10:53:32.029] Mounted inferences to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml-workspace/azureml/9658f6fa-1814-4415-a08c-dee2897bfd53/wd/inferences_workspaceblobstore.\n[2022-08-26T10:53:32.034] Exit __enter__ of DatasetContextManager\nuri entered in sidecar: None\nSet Dataset diabetes_batch's target path to /mnt/batch/tasks/shared/LS_root/jobs/aml-workspace/azureml/9658f6fa-1814-4415-a08c-dee2897bfd53/wd/diabetes_batch_31747bfe-20cb-4296-8624-265194a1a749\nSet OutputDataset inferences's target path to /mnt/batch/tasks/shared/LS_root/jobs/aml-workspace/azureml/9658f6fa-1814-4415-a08c-dee2897bfd53/wd/inferences_workspaceblobstore\n[2022-08-26T10:53:32.035035] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers\n[2022-08-26T10:53:32.043760] INFO azureml.sidecar.task.enter_contexts: New or updated environment variable 'diabetes_batch' with value '/mnt/batch/tasks/shared/LS_root/jobs/aml-workspace/azureml/9658f6fa-1814-4415-a08c-dee2897bfd53/wd/diabetes_batch_31747bfe-20cb-4296-8624-265194a1a749'.\n[2022-08-26T10:53:32.044160] INFO azureml.sidecar.task.enter_contexts: New or updated environment variable 'inferences' with value '/mnt/batch/tasks/shared/LS_root/jobs/aml-workspace/azureml/9658f6fa-1814-4415-a08c-dee2897bfd53/wd/inferences_workspaceblobstore'.\n[2022-08-26T10:53:32.044448] INFO azureml.sidecar.task.enter_contexts: New or updated environment variable 'AZUREML_DATAREFERENCE_diabetes_batch' with value '/mnt/batch/tasks/shared/LS_root/jobs/aml-workspace/azureml/9658f6fa-1814-4415-a08c-dee2897bfd53/wd/diabetes_batch_31747bfe-20cb-4296-8624-265194a1a749'.\n[2022-08-26T10:53:32.044772] INFO azureml.sidecar.task.enter_contexts: New or updated environment variable 'DIABETES_BATCH' with value '/mnt/batch/tasks/shared/LS_root/jobs/aml-workspace/azureml/9658f6fa-1814-4415-a08c-dee2897bfd53/wd/diabetes_batch_31747bfe-20cb-4296-8624-265194a1a749'.\n[2022-08-26T10:53:32.047439] INFO azureml.sidecar.task.enter_contexts: New or updated environment variable 'AZURE_ML_INPUT_diabetes_batch' with value '/mnt/batch/tasks/shared/LS_root/jobs/aml-workspace/azureml/9658f6fa-1814-4415-a08c-dee2897bfd53/wd/diabetes_batch_31747bfe-20cb-4296-8624-265194a1a749'.\n[2022-08-26T10:53:32.047729] INFO azureml.sidecar.task.enter_contexts: New or updated environment variable 'AZURE_ML_OUTPUT_inferences' with value '/mnt/batch/tasks/shared/LS_root/jobs/aml-workspace/azureml/9658f6fa-1814-4415-a08c-dee2897bfd53/wd/inferences_workspaceblobstore'.\n[2022-08-26T10:53:32.047995] INFO azureml.sidecar.task.enter_contexts: New or updated environment variable 'AZUREML_SIDECAR_PATHS_TO_BIND' with value '[\"/mnt/batch/tasks/shared/LS_root/jobs/aml-workspace/azureml/9658f6fa-1814-4415-a08c-dee2897bfd53/wd/diabetes_batch_31747bfe-20cb-4296-8624-265194a1a749:/mnt/batch/tasks/shared/LS_root/jobs/aml-worksp'.\n[2022-08-26T10:53:32.629991] Ran Sidecar prep cmd.\n[2022-08-26T10:53:32.630087] Running Context Managers in Sidecar complete.\n\nStreaming azureml-logs/70_driver_log.txt\n========================================\n2022/08/26 10:54:01 Didn't get JobInfoJson from env, now read from file\n2022/08/26 10:54:01 Suceeded read JobInfoJson from file\n2022/08/26 10:54:01 Starting App Insight Logger for task:  runTaskLet\n2022/08/26 10:54:01 Version: 3.0.02046.0004 Branch: .SourceBranch Commit: a27c02c\n2022/08/26 10:54:01 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/info\n2022/08/26 10:54:01 Send process info logs to master server succeeded\n2022/08/26 10:54:01 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\n2022/08/26 10:54:01 Send process info logs to master server succeeded\n[2022-08-26T10:54:01.990915] Entering context manager injector.\n/azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/lib/python3.6/site-packages/paramiko/transport.py:33: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography and will be removed in a future release.\n  from cryptography.hazmat.backends import default_backend\n[2022-08-26T10:54:02.508210] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['driver/amlbi_main.py', '--client_sdk_version', '1.43.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', 'DatasetOutputConfig:inferences', '--input_fds_0', 'diabetes_batch'])\nScript type = None\n[2022-08-26T10:54:02.511708] Entering Run History Context Manager.\n[2022-08-26T10:54:03.159581] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/aml-workspace/azureml/9658f6fa-1814-4415-a08c-dee2897bfd53/wd/azureml/9658f6fa-1814-4415-a08c-dee2897bfd53\n[2022-08-26T10:54:03.159818] Preparing to call script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.43.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '$AZURE_ML_OUTPUT_inferences', '--input_fds_0', 'diabetes_batch']\n[2022-08-26T10:54:03.159853] After variable expansion, calling script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.43.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/aml-workspace/azureml/9658f6fa-1814-4415-a08c-dee2897bfd53/wd/inferences_workspaceblobstore', '--input_fds_0', 'diabetes_batch']\n\n2022/08/26 10:54:06 Not exporting to RunHistory as the exporter is either stopped or there is no data.\nStopped: false\nOriginalData: 1\nFilteredData: 0.\n\n\n[2022-08-26T10:54:53.108616] The experiment completed successfully. Finalizing run...\nCleaning up all outstanding Run operations, waiting 900.0 seconds\n3 items cleaning up...\nCleanup took 0.14807963371276855 seconds\n[2022-08-26T10:54:53.361108] Finished context manager injector.\n2022/08/26 10:54:54 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\n2022/08/26 10:54:54 Send process info logs to master server succeeded\n2022/08/26 10:54:54 Not exporting to RunHistory as the exporter is either stopped or there is no data.\nStopped: false\nOriginalData: 2\nFilteredData: 0.\n2022/08/26 10:54:54 Process Exiting with Code:  0\n2022/08/26 10:54:54 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n\nStreaming azureml-logs/75_job_post-tvmps_6920dc47fe48bffe69e0d940778b70bf4d99d1f37b655d6c605c31ee26934f31_d.txt\n===============================================================================================================\n[2022-08-26T10:54:54.857879] Entering job release\n[2022-08-26T10:54:55.599679] Starting job release\n[2022-08-26T10:54:55.600083] Logging experiment finalizing status in history service.\nStarting the daemon thread to refresh tokens in background for process with pid = 326\n[2022-08-26T10:54:55.600461] job release stage : upload_datastore starting...\n[2022-08-26T10:54:55.611217] job release stage : start importing azureml.history._tracking in run_history_release.[2022-08-26T10:54:55.611979] Entering context manager injector.\n[2022-08-26T10:54:55.612019] job release stage : execute_job_release starting...\n[2022-08-26T10:54:55.614466] job release stage : copy_batchai_cached_logs starting...\n\n[2022-08-26T10:54:55.614798] job release stage : copy_batchai_cached_logs completed...\n[2022-08-26T10:54:55.619458] job release stage : upload_datastore completed...\n[2022-08-26T10:54:55.724384] job release stage : send_run_telemetry starting...\n[2022-08-26T10:54:55.748366] get vm size and vm region successfully.\n[2022-08-26T10:54:55.756100] get compute meta data successfully.\n[2022-08-26T10:54:55.822935] job release stage : execute_job_release completed...\n[2022-08-26T10:54:55.890076] post artifact meta request successfully.\n[2022-08-26T10:54:55.918717] upload compute record artifact successfully.\n[2022-08-26T10:54:55.918794] job release stage : send_run_telemetry completed...\n[2022-08-26T10:54:55.919093] Running in AzureML-Sidecar, starting to exit user context managers...\n[2022-08-26T10:54:55.919163] Running Sidecar release cmd...\n[2022-08-26T10:54:55.929385] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml-workspace/azureml/9658f6fa-1814-4415-a08c-dee2897bfd53/wd/azureml/9658f6fa-1814-4415-a08c-dee2897bfd53\n[2022-08-26T10:54:55.944] Enter __exit__ of DatasetContextManager\n[2022-08-26T10:54:55.944] Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml-workspace/azureml/9658f6fa-1814-4415-a08c-dee2897bfd53/wd/diabetes_batch_31747bfe-20cb-4296-8624-265194a1a749.\n[2022-08-26T10:54:55.946] Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml-workspace/azureml/9658f6fa-1814-4415-a08c-dee2897bfd53/wd/diabetes_batch_31747bfe-20cb-4296-8624-265194a1a749.\n[2022-08-26T10:54:55.946] Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml-workspace/azureml/9658f6fa-1814-4415-a08c-dee2897bfd53/wd/inferences_workspaceblobstore.\n[2022-08-26T10:54:55.966] Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml-workspace/azureml/9658f6fa-1814-4415-a08c-dee2897bfd53/wd/inferences_workspaceblobstore.\n[2022-08-26T10:54:55.966] Exit __exit__ of DatasetContextManager\n[2022-08-26T10:54:55.966152] Removing absolute paths from host...\n[2022-08-26T10:54:55.966383] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n[2022-08-26T10:54:56.529136] Ran Sidecar release cmd.\n[2022-08-26T10:54:56.529495] Job release is complete\n\nStepRun(batch-score-diabetes) Execution Summary\n================================================\nStepRun( batch-score-diabetes ) Status: Finished\n{'runId': '9658f6fa-1814-4415-a08c-dee2897bfd53', 'target': 'your-compute-cluster', 'status': 'Completed', 'startTimeUtc': '2022-08-26T10:52:38.189922Z', 'endTimeUtc': '2022-08-26T10:55:09.495282Z', 'services': {}, 'properties': {'ContentSnapshotId': 'a60c42c0-a10e-48a4-b0d3-95275d4e80aa', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '65bd5e8b-af0b-4a0b-b4be-1222e1ac3a55', 'azureml.moduleName': 'batch-score-diabetes', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': 'd30b5e20', 'azureml.pipelinerunid': '026e297e-0475-4900-8c4a-42cbb33a064f', 'azureml.pipeline': '026e297e-0475-4900-8c4a-42cbb33a064f', 'azureml.pipelineComponent': 'masterescloud', 'azureml.parallelrunstep': 'true', '_azureml.ComputeTargetType': 'amlctrain', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '31747bfe-20cb-4296-8624-265194a1a749'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'diabetes_batch', 'mechanism': 'Mount'}}], 'outputDatasets': [{'identifier': {'savedId': '9630d374-230b-4de6-8aa4-62698256bc33'}, 'outputType': 'RunOutput', 'outputDetails': {'outputName': 'inferences'}, 'dataset': {\n  \"source\": [\n    \"('workspaceblobstore', 'dataset/9658f6fa-1814-4415-a08c-dee2897bfd53/inferences/')\"\n  ],\n  \"definition\": [\n    \"GetDatastoreFiles\"\n  ],\n  \"registration\": {\n    \"id\": \"9630d374-230b-4de6-8aa4-62698256bc33\",\n    \"name\": null,\n    \"version\": null,\n    \"workspace\": \"Workspace.create(name='aml-workspace', subscription_id='3571f8dc-3527-4993-9d2b-ac0812d807fd', resource_group='aml-resources')\"\n  }\n}}], 'runDefinition': {'script': 'driver/amlbi_main.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--client_sdk_version', '1.43.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', 'DatasetOutputConfig:inferences', '--input_fds_0', 'diabetes_batch'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'your-compute-cluster', 'dataReferences': {}, 'data': {'diabetes_batch': {'dataLocation': {'dataset': {'id': '31747bfe-20cb-4296-8624-265194a1a749', 'name': None, 'version': '1'}, 'dataPath': None, 'uri': None, 'type': None}, 'mechanism': 'Mount', 'environmentVariableName': 'diabetes_batch', 'pathOnCompute': None, 'overwrite': False, 'options': None}}, 'outputData': {'inferences': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'workspaceblobstore', 'relativePath': None}, 'uri': None, 'type': None}, 'mechanism': 'Mount', 'additionalOptions': {'pathOnCompute': None, 'registrationOptions': {'name': None, 'description': None, 'tags': None, 'properties': {'azureml.pipelineRunId': '026e297e-0475-4900-8c4a-42cbb33a064f', 'azureml.pipelineRun.moduleNodeId': 'd30b5e20', 'azureml.pipelineRun.outputPortName': 'inferences'}, 'datasetRegistrationOptions': {'additionalTransformation': None}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}, 'environmentVariableName': None}}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 2, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'experiment_env', 'version': 'Autosave_2022-08-26T10:37:43Z_6635fb69', 'assetId': 'azureml://locations/centralindia/workspaces/c2708a96-e590-4d4f-a0c4-90f52e02261e/environments/experiment_env/versions/Autosave_2022-08-26T10:37:43Z_6635fb69', 'autoRebuild': True, 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'name': 'batch_environment', 'dependencies': ['python=3.6.2', 'scikit-learn', 'pip', {'pip': ['azureml-defaults']}]}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220616.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://amlworkspace2567820123.blob.core.windows.net/azureml/ExperimentRun/dcid.9658f6fa-1814-4415-a08c-dee2897bfd53/azureml-logs/20_image_build_log.txt?sv=2019-07-07&sr=b&sig=eeUVkjCXcI5J64sQM74mGilGr3Ou2jVUaNUu6kpctFg%3D&skoid=deec201d-ebd0-40ef-8887-dbc2d2685f93&sktid=78c76086-2fb7-4f6a-b684-c129ba0ea713&skt=2022-08-26T06%3A49%3A31Z&ske=2022-08-27T14%3A59%3A31Z&sks=b&skv=2019-07-07&st=2022-08-26T10%3A44%3A59Z&se=2022-08-26T18%3A54%3A59Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_6920dc47fe48bffe69e0d940778b70bf4d99d1f37b655d6c605c31ee26934f31_d.txt': 'https://amlworkspace2567820123.blob.core.windows.net/azureml/ExperimentRun/dcid.9658f6fa-1814-4415-a08c-dee2897bfd53/azureml-logs/55_azureml-execution-tvmps_6920dc47fe48bffe69e0d940778b70bf4d99d1f37b655d6c605c31ee26934f31_d.txt?sv=2019-07-07&sr=b&sig=MRBqfRI7J96Fzyi%2FUbm1FMKkyREYvdCe0Myr0tk2gvU%3D&skoid=deec201d-ebd0-40ef-8887-dbc2d2685f93&sktid=78c76086-2fb7-4f6a-b684-c129ba0ea713&skt=2022-08-26T06%3A49%3A31Z&ske=2022-08-27T14%3A59%3A31Z&sks=b&skv=2019-07-07&st=2022-08-26T10%3A44%3A59Z&se=2022-08-26T18%3A54%3A59Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_bb6ae393563fa288a1e65a1b0148a1578a305373bb178ca6d56b99edc6828a2a_d.txt': 'https://amlworkspace2567820123.blob.core.windows.net/azureml/ExperimentRun/dcid.9658f6fa-1814-4415-a08c-dee2897bfd53/azureml-logs/55_azureml-execution-tvmps_bb6ae393563fa288a1e65a1b0148a1578a305373bb178ca6d56b99edc6828a2a_d.txt?sv=2019-07-07&sr=b&sig=bO%2Beg1Gp5FG2WWtNFplh5ukZTVrtjQCvgOH22dojZ5I%3D&skoid=deec201d-ebd0-40ef-8887-dbc2d2685f93&sktid=78c76086-2fb7-4f6a-b684-c129ba0ea713&skt=2022-08-26T06%3A49%3A31Z&ske=2022-08-27T14%3A59%3A31Z&sks=b&skv=2019-07-07&st=2022-08-26T10%3A44%3A59Z&se=2022-08-26T18%3A54%3A59Z&sp=r', 'azureml-logs/65_job_prep-tvmps_6920dc47fe48bffe69e0d940778b70bf4d99d1f37b655d6c605c31ee26934f31_d.txt': 'https://amlworkspace2567820123.blob.core.windows.net/azureml/ExperimentRun/dcid.9658f6fa-1814-4415-a08c-dee2897bfd53/azureml-logs/65_job_prep-tvmps_6920dc47fe48bffe69e0d940778b70bf4d99d1f37b655d6c605c31ee26934f31_d.txt?sv=2019-07-07&sr=b&sig=CKqBHLMh6o1QFD78iAYYhA4xYAim4X54oMKlOiPz4dM%3D&skoid=deec201d-ebd0-40ef-8887-dbc2d2685f93&sktid=78c76086-2fb7-4f6a-b684-c129ba0ea713&skt=2022-08-26T06%3A49%3A31Z&ske=2022-08-27T14%3A59%3A31Z&sks=b&skv=2019-07-07&st=2022-08-26T10%3A44%3A59Z&se=2022-08-26T18%3A54%3A59Z&sp=r', 'azureml-logs/65_job_prep-tvmps_bb6ae393563fa288a1e65a1b0148a1578a305373bb178ca6d56b99edc6828a2a_d.txt': 'https://amlworkspace2567820123.blob.core.windows.net/azureml/ExperimentRun/dcid.9658f6fa-1814-4415-a08c-dee2897bfd53/azureml-logs/65_job_prep-tvmps_bb6ae393563fa288a1e65a1b0148a1578a305373bb178ca6d56b99edc6828a2a_d.txt?sv=2019-07-07&sr=b&sig=FCYxkXycirssZk2wz6iACBuR91Lu0X5cVB9yit7dN%2BI%3D&skoid=deec201d-ebd0-40ef-8887-dbc2d2685f93&sktid=78c76086-2fb7-4f6a-b684-c129ba0ea713&skt=2022-08-26T06%3A49%3A31Z&ske=2022-08-27T14%3A59%3A31Z&sks=b&skv=2019-07-07&st=2022-08-26T10%3A44%3A59Z&se=2022-08-26T18%3A54%3A59Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://amlworkspace2567820123.blob.core.windows.net/azureml/ExperimentRun/dcid.9658f6fa-1814-4415-a08c-dee2897bfd53/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=pz1heWVeQjSjYbbBROKQ1Sj%2Fy3hMBwvaOW6Nho41cCg%3D&skoid=deec201d-ebd0-40ef-8887-dbc2d2685f93&sktid=78c76086-2fb7-4f6a-b684-c129ba0ea713&skt=2022-08-26T06%3A49%3A31Z&ske=2022-08-27T14%3A59%3A31Z&sks=b&skv=2019-07-07&st=2022-08-26T10%3A44%3A59Z&se=2022-08-26T18%3A54%3A59Z&sp=r', 'azureml-logs/75_job_post-tvmps_6920dc47fe48bffe69e0d940778b70bf4d99d1f37b655d6c605c31ee26934f31_d.txt': 'https://amlworkspace2567820123.blob.core.windows.net/azureml/ExperimentRun/dcid.9658f6fa-1814-4415-a08c-dee2897bfd53/azureml-logs/75_job_post-tvmps_6920dc47fe48bffe69e0d940778b70bf4d99d1f37b655d6c605c31ee26934f31_d.txt?sv=2019-07-07&sr=b&sig=RJ1uc3NhS6y%2FHGC6OYaE1tywkdOEsKxwq8XRXcbBs8A%3D&skoid=deec201d-ebd0-40ef-8887-dbc2d2685f93&sktid=78c76086-2fb7-4f6a-b684-c129ba0ea713&skt=2022-08-26T06%3A49%3A31Z&ske=2022-08-27T14%3A59%3A31Z&sks=b&skv=2019-07-07&st=2022-08-26T10%3A44%3A59Z&se=2022-08-26T18%3A54%3A59Z&sp=r', 'azureml-logs/75_job_post-tvmps_bb6ae393563fa288a1e65a1b0148a1578a305373bb178ca6d56b99edc6828a2a_d.txt': 'https://amlworkspace2567820123.blob.core.windows.net/azureml/ExperimentRun/dcid.9658f6fa-1814-4415-a08c-dee2897bfd53/azureml-logs/75_job_post-tvmps_bb6ae393563fa288a1e65a1b0148a1578a305373bb178ca6d56b99edc6828a2a_d.txt?sv=2019-07-07&sr=b&sig=mqEhoL6kQOPpXRanRnq7LlKcS9S09ZqyupUsFGYspms%3D&skoid=deec201d-ebd0-40ef-8887-dbc2d2685f93&sktid=78c76086-2fb7-4f6a-b684-c129ba0ea713&skt=2022-08-26T06%3A49%3A31Z&ske=2022-08-27T14%3A59%3A31Z&sks=b&skv=2019-07-07&st=2022-08-26T10%3A44%3A59Z&se=2022-08-26T18%3A54%3A59Z&sp=r', 'azureml-logs/process_info.json': 'https://amlworkspace2567820123.blob.core.windows.net/azureml/ExperimentRun/dcid.9658f6fa-1814-4415-a08c-dee2897bfd53/azureml-logs/process_info.json?sv=2019-07-07&sr=b&sig=xjd%2FvhPcRufFVUPakgAvSd02PBT0Nx6MMsAyEhG%2B374%3D&skoid=deec201d-ebd0-40ef-8887-dbc2d2685f93&sktid=78c76086-2fb7-4f6a-b684-c129ba0ea713&skt=2022-08-26T06%3A49%3A31Z&ske=2022-08-27T14%3A59%3A31Z&sks=b&skv=2019-07-07&st=2022-08-26T10%3A44%3A59Z&se=2022-08-26T18%3A54%3A59Z&sp=r', 'azureml-logs/process_status.json': 'https://amlworkspace2567820123.blob.core.windows.net/azureml/ExperimentRun/dcid.9658f6fa-1814-4415-a08c-dee2897bfd53/azureml-logs/process_status.json?sv=2019-07-07&sr=b&sig=2Z%2F4zabS8DkOTtrabKXJJKrzE0vT1cWleyLEnNOKI3w%3D&skoid=deec201d-ebd0-40ef-8887-dbc2d2685f93&sktid=78c76086-2fb7-4f6a-b684-c129ba0ea713&skt=2022-08-26T06%3A49%3A31Z&ske=2022-08-27T14%3A59%3A31Z&sks=b&skv=2019-07-07&st=2022-08-26T10%3A44%3A59Z&se=2022-08-26T18%3A54%3A59Z&sp=r', 'logs/azureml/119_azureml.log': 'https://amlworkspace2567820123.blob.core.windows.net/azureml/ExperimentRun/dcid.9658f6fa-1814-4415-a08c-dee2897bfd53/logs/azureml/119_azureml.log?sv=2019-07-07&sr=b&sig=N52PdVdqYs%2B9ukgeFY2MbwQi0uH%2FRJYpIcIH37Oe1v0%3D&skoid=deec201d-ebd0-40ef-8887-dbc2d2685f93&sktid=78c76086-2fb7-4f6a-b684-c129ba0ea713&skt=2022-08-26T06%3A49%3A31Z&ske=2022-08-27T14%3A59%3A31Z&sks=b&skv=2019-07-07&st=2022-08-26T10%3A44%3A59Z&se=2022-08-26T18%3A54%3A59Z&sp=r', 'logs/azureml/89_azureml.log': 'https://amlworkspace2567820123.blob.core.windows.net/azureml/ExperimentRun/dcid.9658f6fa-1814-4415-a08c-dee2897bfd53/logs/azureml/89_azureml.log?sv=2019-07-07&sr=b&sig=aUy957YEX%2FhuT5oqtUV4NVnNWS19tsEKN9VGiAUcnIc%3D&skoid=deec201d-ebd0-40ef-8887-dbc2d2685f93&sktid=78c76086-2fb7-4f6a-b684-c129ba0ea713&skt=2022-08-26T06%3A49%3A31Z&ske=2022-08-27T14%3A59%3A31Z&sks=b&skv=2019-07-07&st=2022-08-26T10%3A44%3A59Z&se=2022-08-26T18%3A54%3A59Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://amlworkspace2567820123.blob.core.windows.net/azureml/ExperimentRun/dcid.9658f6fa-1814-4415-a08c-dee2897bfd53/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=D1nlooa8scRNm31ROc6ZRozgglsh%2BJ%2BmufYqp30nEW4%3D&skoid=deec201d-ebd0-40ef-8887-dbc2d2685f93&sktid=78c76086-2fb7-4f6a-b684-c129ba0ea713&skt=2022-08-26T06%3A49%3A31Z&ske=2022-08-27T14%3A59%3A31Z&sks=b&skv=2019-07-07&st=2022-08-26T10%3A44%3A59Z&se=2022-08-26T18%3A54%3A59Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://amlworkspace2567820123.blob.core.windows.net/azureml/ExperimentRun/dcid.9658f6fa-1814-4415-a08c-dee2897bfd53/logs/azureml/job_prep_azureml.log?sv=2019-07-07&sr=b&sig=qQzLUc55ogNdkEyiKF5eaZUL7i7djWQVY8OdLjvTFMU%3D&skoid=deec201d-ebd0-40ef-8887-dbc2d2685f93&sktid=78c76086-2fb7-4f6a-b684-c129ba0ea713&skt=2022-08-26T06%3A49%3A31Z&ske=2022-08-27T14%3A59%3A31Z&sks=b&skv=2019-07-07&st=2022-08-26T10%3A44%3A59Z&se=2022-08-26T18%3A54%3A59Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://amlworkspace2567820123.blob.core.windows.net/azureml/ExperimentRun/dcid.9658f6fa-1814-4415-a08c-dee2897bfd53/logs/azureml/job_release_azureml.log?sv=2019-07-07&sr=b&sig=aB14LotI5e698ynOjk1IJwml6wj%2FDGHKKmsl1Ib25ck%3D&skoid=deec201d-ebd0-40ef-8887-dbc2d2685f93&sktid=78c76086-2fb7-4f6a-b684-c129ba0ea713&skt=2022-08-26T06%3A49%3A31Z&ske=2022-08-27T14%3A59%3A31Z&sks=b&skv=2019-07-07&st=2022-08-26T10%3A44%3A59Z&se=2022-08-26T18%3A54%3A59Z&sp=r', 'logs/azureml/sidecar/tvmps_6920dc47fe48bffe69e0d940778b70bf4d99d1f37b655d6c605c31ee26934f31_d/all.log': 'https://amlworkspace2567820123.blob.core.windows.net/azureml/ExperimentRun/dcid.9658f6fa-1814-4415-a08c-dee2897bfd53/logs/azureml/sidecar/tvmps_6920dc47fe48bffe69e0d940778b70bf4d99d1f37b655d6c605c31ee26934f31_d/all.log?sv=2019-07-07&sr=b&sig=1Ak4nYF%2BRnJf1TgxZco8Y6c%2BQHrFQI%2BmMUPi0V%2F7Dsw%3D&skoid=deec201d-ebd0-40ef-8887-dbc2d2685f93&sktid=78c76086-2fb7-4f6a-b684-c129ba0ea713&skt=2022-08-26T06%3A49%3A31Z&ske=2022-08-27T14%3A59%3A31Z&sks=b&skv=2019-07-07&st=2022-08-26T10%3A44%3A59Z&se=2022-08-26T18%3A54%3A59Z&sp=r', 'logs/azureml/sidecar/tvmps_6920dc47fe48bffe69e0d940778b70bf4d99d1f37b655d6c605c31ee26934f31_d/task.enter_contexts.log': 'https://amlworkspace2567820123.blob.core.windows.net/azureml/ExperimentRun/dcid.9658f6fa-1814-4415-a08c-dee2897bfd53/logs/azureml/sidecar/tvmps_6920dc47fe48bffe69e0d940778b70bf4d99d1f37b655d6c605c31ee26934f31_d/task.enter_contexts.log?sv=2019-07-07&sr=b&sig=v7gbbPN1bE15p8E1Wlv%2FTYjnmkLWaNUxMuGyJN4IlEs%3D&skoid=deec201d-ebd0-40ef-8887-dbc2d2685f93&sktid=78c76086-2fb7-4f6a-b684-c129ba0ea713&skt=2022-08-26T06%3A49%3A31Z&ske=2022-08-27T14%3A59%3A31Z&sks=b&skv=2019-07-07&st=2022-08-26T10%3A44%3A59Z&se=2022-08-26T18%3A54%3A59Z&sp=r', 'logs/azureml/sidecar/tvmps_6920dc47fe48bffe69e0d940778b70bf4d99d1f37b655d6c605c31ee26934f31_d/task.exit_contexts.log': 'https://amlworkspace2567820123.blob.core.windows.net/azureml/ExperimentRun/dcid.9658f6fa-1814-4415-a08c-dee2897bfd53/logs/azureml/sidecar/tvmps_6920dc47fe48bffe69e0d940778b70bf4d99d1f37b655d6c605c31ee26934f31_d/task.exit_contexts.log?sv=2019-07-07&sr=b&sig=pXFZzIi6s50TnT%2Fx14EeWa9iyKtr3evADGkZ8uoqMKE%3D&skoid=deec201d-ebd0-40ef-8887-dbc2d2685f93&sktid=78c76086-2fb7-4f6a-b684-c129ba0ea713&skt=2022-08-26T06%3A49%3A31Z&ske=2022-08-27T14%3A59%3A31Z&sks=b&skv=2019-07-07&st=2022-08-26T10%3A44%3A59Z&se=2022-08-26T18%3A54%3A59Z&sp=r', 'logs/azureml/sidecar/tvmps_bb6ae393563fa288a1e65a1b0148a1578a305373bb178ca6d56b99edc6828a2a_d/all.log': 'https://amlworkspace2567820123.blob.core.windows.net/azureml/ExperimentRun/dcid.9658f6fa-1814-4415-a08c-dee2897bfd53/logs/azureml/sidecar/tvmps_bb6ae393563fa288a1e65a1b0148a1578a305373bb178ca6d56b99edc6828a2a_d/all.log?sv=2019-07-07&sr=b&sig=D%2FhXY%2FkoDVQtiYf2QMgA%2FoEN7TSY9%2BzF2VXHw4NTpmE%3D&skoid=deec201d-ebd0-40ef-8887-dbc2d2685f93&sktid=78c76086-2fb7-4f6a-b684-c129ba0ea713&skt=2022-08-26T06%3A49%3A31Z&ske=2022-08-27T14%3A59%3A31Z&sks=b&skv=2019-07-07&st=2022-08-26T10%3A44%3A59Z&se=2022-08-26T18%3A54%3A59Z&sp=r', 'logs/azureml/sidecar/tvmps_bb6ae393563fa288a1e65a1b0148a1578a305373bb178ca6d56b99edc6828a2a_d/task.enter_contexts.log': 'https://amlworkspace2567820123.blob.core.windows.net/azureml/ExperimentRun/dcid.9658f6fa-1814-4415-a08c-dee2897bfd53/logs/azureml/sidecar/tvmps_bb6ae393563fa288a1e65a1b0148a1578a305373bb178ca6d56b99edc6828a2a_d/task.enter_contexts.log?sv=2019-07-07&sr=b&sig=FwvOoNJ73VM7Lag1xw1fqQzIJoAygqsvhcDlTXx0Xig%3D&skoid=deec201d-ebd0-40ef-8887-dbc2d2685f93&sktid=78c76086-2fb7-4f6a-b684-c129ba0ea713&skt=2022-08-26T06%3A49%3A31Z&ske=2022-08-27T14%3A59%3A31Z&sks=b&skv=2019-07-07&st=2022-08-26T10%3A44%3A59Z&se=2022-08-26T18%3A54%3A59Z&sp=r', 'logs/azureml/sidecar/tvmps_bb6ae393563fa288a1e65a1b0148a1578a305373bb178ca6d56b99edc6828a2a_d/task.exit_contexts.log': 'https://amlworkspace2567820123.blob.core.windows.net/azureml/ExperimentRun/dcid.9658f6fa-1814-4415-a08c-dee2897bfd53/logs/azureml/sidecar/tvmps_bb6ae393563fa288a1e65a1b0148a1578a305373bb178ca6d56b99edc6828a2a_d/task.exit_contexts.log?sv=2019-07-07&sr=b&sig=56L4qPKPFN2agr%2B%2BPXM623sYVXCpcuYdL4SFt8LZIgI%3D&skoid=deec201d-ebd0-40ef-8887-dbc2d2685f93&sktid=78c76086-2fb7-4f6a-b684-c129ba0ea713&skt=2022-08-26T06%3A49%3A31Z&ske=2022-08-27T14%3A59%3A31Z&sks=b&skv=2019-07-07&st=2022-08-26T10%3A44%3A59Z&se=2022-08-26T18%3A54%3A59Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://amlworkspace2567820123.blob.core.windows.net/azureml/ExperimentRun/dcid.9658f6fa-1814-4415-a08c-dee2897bfd53/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=h5FrSCe1YWzXWkGsp5keeA2zVrzjsX85jT1U9tkzsFI%3D&skoid=deec201d-ebd0-40ef-8887-dbc2d2685f93&sktid=78c76086-2fb7-4f6a-b684-c129ba0ea713&skt=2022-08-26T06%3A49%3A31Z&ske=2022-08-27T14%3A59%3A31Z&sks=b&skv=2019-07-07&st=2022-08-26T10%3A44%3A59Z&se=2022-08-26T18%3A54%3A59Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://amlworkspace2567820123.blob.core.windows.net/azureml/ExperimentRun/dcid.9658f6fa-1814-4415-a08c-dee2897bfd53/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=GcyqFLk2lr8Un%2FO1pOoI10h9JegOtOEheYqkjL52FbI%3D&skoid=deec201d-ebd0-40ef-8887-dbc2d2685f93&sktid=78c76086-2fb7-4f6a-b684-c129ba0ea713&skt=2022-08-26T06%3A49%3A31Z&ske=2022-08-27T14%3A59%3A31Z&sks=b&skv=2019-07-07&st=2022-08-26T10%3A44%3A59Z&se=2022-08-26T18%3A54%3A59Z&sp=r'}, 'submittedBy': 'Neeresh Kumar Perla'}\n\n\n\nPipelineRun Execution Summary\n==============================\nPipelineRun Status: Finished\n{'runId': '026e297e-0475-4900-8c4a-42cbb33a064f', 'status': 'Completed', 'startTimeUtc': '2022-08-26T10:36:43.316446Z', 'endTimeUtc': '2022-08-26T10:55:11.709273Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}', 'azureml.continue_on_step_failure': 'False', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.pipelineComponent': 'pipelinerun'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://amlworkspace2567820123.blob.core.windows.net/azureml/ExperimentRun/dcid.026e297e-0475-4900-8c4a-42cbb33a064f/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=W4d8Dnj6nlDfjikufpq5lUj9Yi9Jgdq2Pi1SWhO%2BgcA%3D&skoid=deec201d-ebd0-40ef-8887-dbc2d2685f93&sktid=78c76086-2fb7-4f6a-b684-c129ba0ea713&skt=2022-08-26T06%3A49%3A31Z&ske=2022-08-27T14%3A59%3A31Z&sks=b&skv=2019-07-07&st=2022-08-26T10%3A45%3A13Z&se=2022-08-26T18%3A55%3A13Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://amlworkspace2567820123.blob.core.windows.net/azureml/ExperimentRun/dcid.026e297e-0475-4900-8c4a-42cbb33a064f/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=Xmi6OaRbJZ0F2PqNyI6M8YKXRSEsWN48epvKZUYvzI0%3D&skoid=deec201d-ebd0-40ef-8887-dbc2d2685f93&sktid=78c76086-2fb7-4f6a-b684-c129ba0ea713&skt=2022-08-26T06%3A49%3A31Z&ske=2022-08-27T14%3A59%3A31Z&sks=b&skv=2019-07-07&st=2022-08-26T10%3A45%3A13Z&se=2022-08-26T18%3A55%3A13Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://amlworkspace2567820123.blob.core.windows.net/azureml/ExperimentRun/dcid.026e297e-0475-4900-8c4a-42cbb33a064f/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=IPGGOQ2r51Lbl%2F%2FE%2FBEkGGrM9icTF7tmuDTjFyG1DdY%3D&skoid=deec201d-ebd0-40ef-8887-dbc2d2685f93&sktid=78c76086-2fb7-4f6a-b684-c129ba0ea713&skt=2022-08-26T06%3A49%3A31Z&ske=2022-08-27T14%3A59%3A31Z&sks=b&skv=2019-07-07&st=2022-08-26T10%3A45%3A13Z&se=2022-08-26T18%3A55%3A13Z&sp=r'}, 'submittedBy': 'Neeresh Kumar Perla'}\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "'Finished'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661511316467
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\r\n",
        "import shutil\r\n",
        "\r\n",
        "# Remove the local results folder if left over from a previous run\r\n",
        "shutil.rmtree('diabetes-results', ignore_errors=True)\r\n",
        "\r\n",
        "# Get the run for the first step and download its output\r\n",
        "prediction_run = next(pipeline_run.get_children())\r\n",
        "prediction_output = prediction_run.get_output_data('inferences')\r\n",
        "prediction_output.download(local_path='diabetes-results')\r\n",
        "\r\n",
        "# Traverse the folder hierarchy and find the results file\r\n",
        "for root, dirs, files in os.walk('diabetes-results'):\r\n",
        "    for file in files:\r\n",
        "        if file.endswith('parallel_run_step.txt'):\r\n",
        "            result_file = os.path.join(root,file)\r\n",
        "\r\n",
        "# cleanup output format\r\n",
        "df = pd.read_csv(result_file, delimiter=\":\", header=None)\r\n",
        "df.columns = [\"File\", \"Prediction\"]\r\n",
        "\r\n",
        "# Display the first 20 results\r\n",
        "df.head(20)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "      File  Prediction\n0   11.csv           0\n1   12.csv           0\n2   13.csv           0\n3   14.csv           0\n4   15.csv           1\n5   16.csv           0\n6   17.csv           0\n7   18.csv           0\n8   19.csv           0\n9    2.csv           1\n10  20.csv           0\n11  21.csv           0\n12  22.csv           0\n13  23.csv           0\n14  24.csv           0\n15  25.csv           1\n16  26.csv           1\n17  27.csv           0\n18  28.csv           0\n19  29.csv           0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>File</th>\n      <th>Prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>12.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>15.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>16.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>17.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>18.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>19.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>20.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>21.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>22.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>23.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>24.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>25.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>26.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>27.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>28.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>29.csv</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661511698282
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Publishing the Pipeline"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "published_pipeline = pipeline_run.publish_pipeline(name = 'diabetes-batch-pipeline', description='Batch scoring of diabetes data', version='1.0')\r\n",
        "\r\n",
        "published_pipeline"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "Pipeline(Name: diabetes-batch-pipeline,\nId: 973c51a5-42d1-4fdb-8562-7a092d097d5f,\nStatus: Active,\nEndpoint: https://centralindia.api.azureml.ms/pipelines/v1.0/subscriptions/3571f8dc-3527-4993-9d2b-ac0812d807fd/resourceGroups/aml-resources/providers/Microsoft.MachineLearningServices/workspaces/aml-workspace/PipelineRuns/PipelineSubmit/973c51a5-42d1-4fdb-8562-7a092d097d5f)",
            "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>diabetes-batch-pipeline</td><td><a href=\"https://ml.azure.com/pipelines/973c51a5-42d1-4fdb-8562-7a092d097d5f?wsid=/subscriptions/3571f8dc-3527-4993-9d2b-ac0812d807fd/resourcegroups/aml-resources/workspaces/aml-workspace\" target=\"_blank\" rel=\"noopener\">973c51a5-42d1-4fdb-8562-7a092d097d5f</a></td><td>Active</td><td><a href=\"https://centralindia.api.azureml.ms/pipelines/v1.0/subscriptions/3571f8dc-3527-4993-9d2b-ac0812d807fd/resourceGroups/aml-resources/providers/Microsoft.MachineLearningServices/workspaces/aml-workspace/PipelineRuns/PipelineSubmit/973c51a5-42d1-4fdb-8562-7a092d097d5f\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661511856067
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rest_endpoint = published_pipeline.endpoint\r\n",
        "rest_endpoint"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "'https://centralindia.api.azureml.ms/pipelines/v1.0/subscriptions/3571f8dc-3527-4993-9d2b-ac0812d807fd/resourceGroups/aml-resources/providers/Microsoft.MachineLearningServices/workspaces/aml-workspace/PipelineRuns/PipelineSubmit/973c51a5-42d1-4fdb-8562-7a092d097d5f'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661511905662
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To use the endpoint, client applications need to make a REST call over HTTP. This request must be authenticated, so an authorization header is required. To test this out, we'll use the authorization header from your current connection to your Azure workspace, which you can get using the following code:**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.authentication import InteractiveLoginAuthentication\r\n",
        "\r\n",
        "from azureml.core.authentication import InteractiveLoginAuthentication\r\n",
        "\r\n",
        "interactive_auth = InteractiveLoginAuthentication()\r\n",
        "auth_header = interactive_auth.get_authentication_header()\r\n",
        "print('Authentication header ready.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Authentication header ready.\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661512604257
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\r\n",
        "\r\n",
        "rest_endpoint = published_pipeline.endpoint\r\n",
        "response = requests.post(rest_endpoint, \r\n",
        "                         headers=auth_header, \r\n",
        "                         json={\"ExperimentName\": \"mslearn-diabetes-batch\"})\r\n",
        "run_id = response.json()[\"Id\"]\r\n",
        "run_id"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "'eb687dc4-3cf9-4c16-b0d7-47227893bb99'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661512625239
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core.run import PipelineRun\r\n",
        "from azureml.widgets import RunDetails\r\n",
        "\r\n",
        "published_pipeline_run = PipelineRun(ws.experiments['mslearn-diabetes-batch'], run_id)\r\n",
        "\r\n",
        "# Block until the run completes\r\n",
        "published_pipeline_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "PipelineRunId: eb687dc4-3cf9-4c16-b0d7-47227893bb99\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/eb687dc4-3cf9-4c16-b0d7-47227893bb99?wsid=/subscriptions/3571f8dc-3527-4993-9d2b-ac0812d807fd/resourcegroups/aml-resources/workspaces/aml-workspace&tid=78c76086-2fb7-4f6a-b684-c129ba0ea713\n\nPipelineRun Execution Summary\n==============================\nPipelineRun Status: Finished\n{'runId': 'eb687dc4-3cf9-4c16-b0d7-47227893bb99', 'status': 'Completed', 'startTimeUtc': '2022-08-26T11:17:04.829683Z', 'endTimeUtc': '2022-08-26T11:17:06.342999Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'Unavailable', 'runType': 'HTTP', 'azureml.parameters': '{}', 'azureml.continue_on_step_failure': 'False', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.pipelineid': '973c51a5-42d1-4fdb-8562-7a092d097d5f', 'azureml.pipelineComponent': 'pipelinerun'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://amlworkspace2567820123.blob.core.windows.net/azureml/ExperimentRun/dcid.eb687dc4-3cf9-4c16-b0d7-47227893bb99/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=Ta69%2F%2FHyuIUuKLUZln7KK0u861IYSI%2F6ZX0vIW1oQf4%3D&skoid=deec201d-ebd0-40ef-8887-dbc2d2685f93&sktid=78c76086-2fb7-4f6a-b684-c129ba0ea713&skt=2022-08-26T06%3A49%3A31Z&ske=2022-08-27T14%3A59%3A31Z&sks=b&skv=2019-07-07&st=2022-08-26T11%3A07%3A09Z&se=2022-08-26T19%3A17%3A09Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://amlworkspace2567820123.blob.core.windows.net/azureml/ExperimentRun/dcid.eb687dc4-3cf9-4c16-b0d7-47227893bb99/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=9dDWMN56zOI0Wzrj9Be70B%2B2snd2I%2Fyd%2FeJqpKJGAvc%3D&skoid=deec201d-ebd0-40ef-8887-dbc2d2685f93&sktid=78c76086-2fb7-4f6a-b684-c129ba0ea713&skt=2022-08-26T06%3A49%3A31Z&ske=2022-08-27T14%3A59%3A31Z&sks=b&skv=2019-07-07&st=2022-08-26T11%3A07%3A09Z&se=2022-08-26T19%3A17%3A09Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://amlworkspace2567820123.blob.core.windows.net/azureml/ExperimentRun/dcid.eb687dc4-3cf9-4c16-b0d7-47227893bb99/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=oOsEFFl0kS8VpUIY%2BCy%2B%2BbEjzcbgb3PuUbOGiaGlCSY%3D&skoid=deec201d-ebd0-40ef-8887-dbc2d2685f93&sktid=78c76086-2fb7-4f6a-b684-c129ba0ea713&skt=2022-08-26T06%3A49%3A31Z&ske=2022-08-27T14%3A59%3A31Z&sks=b&skv=2019-07-07&st=2022-08-26T11%3A07%3A09Z&se=2022-08-26T19%3A17%3A09Z&sp=r'}, 'submittedBy': 'Neeresh Kumar Perla'}\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "'Finished'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661512632823
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\r\n",
        "import shutil\r\n",
        "\r\n",
        "# Remove the local results folder if left over from a previous run\r\n",
        "shutil.rmtree('diabetes-results', ignore_errors=True)\r\n",
        "\r\n",
        "# Get the run for the first step and download its output\r\n",
        "prediction_run = next(pipeline_run.get_children())\r\n",
        "prediction_output = prediction_run.get_output_data('inferences')\r\n",
        "prediction_output.download(local_path='diabetes-results')\r\n",
        "\r\n",
        "# Traverse the folder hierarchy and find the results file\r\n",
        "for root, dirs, files in os.walk('diabetes-results'):\r\n",
        "    for file in files:\r\n",
        "        if file.endswith('parallel_run_step.txt'):\r\n",
        "            result_file = os.path.join(root,file)\r\n",
        "\r\n",
        "# cleanup output format\r\n",
        "df = pd.read_csv(result_file, delimiter=\":\", header=None)\r\n",
        "df.columns = [\"File\", \"Prediction\"]\r\n",
        "\r\n",
        "# Display the first 20 results\r\n",
        "df.head(20)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": "      File  Prediction\n0   11.csv           0\n1   12.csv           0\n2   13.csv           0\n3   14.csv           0\n4   15.csv           1\n5   16.csv           0\n6   17.csv           0\n7   18.csv           0\n8   19.csv           0\n9    2.csv           1\n10  20.csv           0\n11  21.csv           0\n12  22.csv           0\n13  23.csv           0\n14  24.csv           0\n15  25.csv           1\n16  26.csv           1\n17  27.csv           0\n18  28.csv           0\n19  29.csv           0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>File</th>\n      <th>Prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>12.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>15.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>16.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>17.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>18.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>19.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>20.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>21.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>22.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>23.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>24.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>25.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>26.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>27.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>28.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>29.csv</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661512641010
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}